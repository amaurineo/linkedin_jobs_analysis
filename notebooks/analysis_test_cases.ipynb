{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5969dbdc",
   "metadata": {},
   "source": [
    "# Skill extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8c850aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Get the project root directory (e.g., linkedin_jobs_analysis/)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add project root to sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from src.utils.logger import setup_logging\n",
    "from src.analysis.extracting_skills_list import SkillExtractor\n",
    "from config.analysis import STANDARD_SKILL_MAP\n",
    "\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47d60fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_skill_extractor(test_cases = [\n",
    "        (\n",
    "            \"Precisamos de um profissional com experiência em Python e SQL.\",\n",
    "            ['Python', 'SQL']\n",
    "        ),\n",
    "        (\n",
    "            \"Conhecimento em Machine Learning (ML) e PowerBI é essencial.\",\n",
    "            ['Machine Learning', 'Power BI']\n",
    "        ),\n",
    "        (\n",
    "            \"Domínio de AWS, Azure e GCP para cloud computing.\",\n",
    "            ['Cloud', 'AWS', 'Azure', 'GCP']\n",
    "        ),\n",
    "        (\n",
    "            \"Experiência com PySpark e Spark para processamento de dados.\",\n",
    "            ['Spark']\n",
    "        ),\n",
    "        (\n",
    "            \"Habilidade em Excel avançado e análise de dados.\",\n",
    "            ['Excel']\n",
    "        ),\n",
    "        (\n",
    "            \"Conhecimento em Airflow para orquestração de pipelines.\",\n",
    "            ['Airflow']\n",
    "        ),\n",
    "        (\n",
    "            \"Não há requisitos técnicos específicos para esta vaga.\",\n",
    "            []\n",
    "        ),\n",
    "        (\n",
    "            \"Necessário conhecimento em Python e pandas para análise de dados.\",\n",
    "            ['Python', 'Pandas']\n",
    "        ),\n",
    "        (\n",
    "            \"A palavra 'excelente' não deve ser confundida com 3xc3l.\",\n",
    "            []\n",
    "        ),\n",
    "        (\n",
    "            \"MLOps e Machine Learning são importantes para a vaga.\",\n",
    "            ['Machine Learning']  # Assuming MLOps isn't in our test skills\n",
    "        )\n",
    "    ]):\n",
    "    \"\"\"Test function for SkillExtractor with various edge cases\"\"\"\n",
    "\n",
    "    extractor = SkillExtractor(STANDARD_SKILL_MAP)\n",
    "    \n",
    "    passed = 0\n",
    "    failed = 0\n",
    "    failed_cases = []\n",
    "    \n",
    "    for text, expected in test_cases:\n",
    "        try:\n",
    "            result = extractor.extract_skills(text)\n",
    "            result_set = set(result)\n",
    "            expected_set = set(expected)\n",
    "            \n",
    "            # Check for missing skills\n",
    "            missing = expected_set - result_set\n",
    "            # Check for extra skills (only fail if we got completely unexpected skills)\n",
    "            extra = result_set - expected_set\n",
    "            print(extra)\n",
    "            if not missing and not extra:\n",
    "                passed += 1\n",
    "                print(f\"PASS: '{text}' -> {result}\")\n",
    "            else:\n",
    "                failed += 1\n",
    "                failed_cases.append({\n",
    "                    'text': text,\n",
    "                    'expected': expected,\n",
    "                    'got': result,\n",
    "                    'missing': list(missing),\n",
    "                    'extra': list(extra)\n",
    "                })\n",
    "                print(f\"FAIL: '{text}'\")\n",
    "                print(f\"  Expected: {expected}\")\n",
    "                print(f\"  Got:      {result}\")\n",
    "                if missing:\n",
    "                    print(f\"  Missing:  {list(missing)}\")\n",
    "                if extra:\n",
    "                    print(f\"  Extra:    {list(extra)}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            failed += 1\n",
    "            failed_cases.append({\n",
    "                'text': text,\n",
    "                'error': str(e)\n",
    "            })\n",
    "            print(f\"ERROR processing: '{text}' - {str(e)}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nTest Results: {passed} passed, {failed} failed\")\n",
    "    \n",
    "    if failed_cases:\n",
    "        print(\"\\nFailed Cases Summary:\")\n",
    "        for case in failed_cases:\n",
    "            if 'error' in case:\n",
    "                print(f\"Text: '{case['text']}'\")\n",
    "                print(f\"Error: {case['error']}\")\n",
    "            else:\n",
    "                print(f\"Text: '{case['text']}'\")\n",
    "                print(f\"Expected: {case['expected']}\")\n",
    "                print(f\"Got:      {case['got']}\")\n",
    "                if case['missing']:\n",
    "                    print(f\"Missing:  {case['missing']}\")\n",
    "                if case['extra']:\n",
    "                    print(f\"Extra:    {case['extra']}\")\n",
    "            print(\"---\")\n",
    "    \n",
    "    return {\n",
    "        'passed': passed,\n",
    "        'failed': failed,\n",
    "        'failed_cases': failed_cases,\n",
    "        'success_rate': passed / (passed + failed) if (passed + failed) > 0 else 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "157e58b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 17:30:52,946 - src.analysis.extracting_skills_list - SUCCESS - Successfully loaded spaCy model: pt_core_news_lg\n",
      "2025-05-18 17:30:52,948 - src.analysis.extracting_skills_list - INFO - Prepared regex patterns for 126 skills.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MLOps']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skills_list = [skill for synonyms in STANDARD_SKILL_MAP.values() for skill in synonyms]\n",
    "extractor = SkillExtractor(STANDARD_SKILL_MAP)\n",
    "text = 'MLOps são importantes para a vaga.'\n",
    "extractor.extract_skills(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4da6324d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 17:30:30,647 - src.analysis.extracting_skills_list - SUCCESS - Successfully loaded spaCy model: pt_core_news_lg\n",
      "2025-05-18 17:30:30,648 - src.analysis.extracting_skills_list - INFO - Prepared regex patterns for 126 skills.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "PASS: 'Precisamos de um profissional com experiência em Python e SQL.' -> ['SQL', 'Python']\n",
      "set()\n",
      "PASS: 'Conhecimento em Machine Learning (ML) e PowerBI é essencial.' -> ['Power BI', 'Machine Learning']\n",
      "set()\n",
      "PASS: 'Domínio de AWS, Azure e GCP para cloud computing.' -> ['AWS', 'GCP', 'Azure', 'Cloud']\n",
      "set()\n",
      "PASS: 'Experiência com PySpark e Spark para processamento de dados.' -> ['Spark']\n",
      "set()\n",
      "PASS: 'Habilidade em Excel avançado e análise de dados.' -> ['Excel']\n",
      "set()\n",
      "PASS: 'Conhecimento em Airflow para orquestração de pipelines.' -> ['Airflow']\n",
      "set()\n",
      "PASS: 'Não há requisitos técnicos específicos para esta vaga.' -> []\n",
      "set()\n",
      "PASS: 'Necessário conhecimento em Python e pandas para análise de dados.' -> ['Pandas', 'Python']\n",
      "set()\n",
      "PASS: 'A palavra 'excelente' não deve ser confundida com 3xc3l.' -> []\n",
      "{'MLOps'}\n",
      "FAIL: 'MLOps e Machine Learning são importantes para a vaga.'\n",
      "  Expected: ['Machine Learning']\n",
      "  Got:      ['Machine Learning', 'MLOps']\n",
      "  Extra:    ['MLOps']\n",
      "\n",
      "Test Results: 9 passed, 1 failed\n",
      "\n",
      "Failed Cases Summary:\n",
      "Text: 'MLOps e Machine Learning são importantes para a vaga.'\n",
      "Expected: ['Machine Learning']\n",
      "Got:      ['Machine Learning', 'MLOps']\n",
      "Extra:    ['MLOps']\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'passed': 9,\n",
       " 'failed': 1,\n",
       " 'failed_cases': [{'text': 'MLOps e Machine Learning são importantes para a vaga.',\n",
       "   'expected': ['Machine Learning'],\n",
       "   'got': ['Machine Learning', 'MLOps'],\n",
       "   'missing': [],\n",
       "   'extra': ['MLOps']}],\n",
       " 'success_rate': 0.9}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_skill_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6050cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.read_csv('../data/processed/df_jobs_classified.csv')\n",
    "skills = pd.read_csv('../data/processed/df_skills.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d72d1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa6c0481",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b6f868",
   "metadata": {},
   "source": [
    "# Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766cbe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Dict, List\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf3701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the project root directory (e.g., linkedin_jobs_analysis/)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add project root to sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Now import from src\n",
    "from config.analysis import ROLE_PATTERNS, SPECIAL_CASES\n",
    "from src.analysis.analysis_utils import test_classifier, title_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ced0da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test results: 24 passed, 0 failed out of 24 cases.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Logger' object has no attribute 'success'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtest_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pschm\\OneDrive\\eng\\projetos\\linkedin_jobs_analysis\\src\\analysis\\analysis_utils.py:183\u001b[39m, in \u001b[36mtest_classifier\u001b[39m\u001b[34m(test_cases)\u001b[39m\n\u001b[32m    181\u001b[39m     logger.error(summary_message)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     \u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuccess\u001b[49m(summary_message)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Logger' object has no attribute 'success'"
     ]
    }
   ],
   "source": [
    "test_classifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d8314b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Analista de Dados'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_classifier('Analista de dados e automação com IA - Pleno\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e99dfcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAIL: 'Analista de dados e automação com IA - Pleno'\n",
      "  Expected: Engenheiro de IA\n",
      "  Got:      Analista de Dados\n",
      "FAIL: 'Engenheiro (a) de IA'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de IA\n",
      "FAIL: 'Engenheiro (a) de Automação Sr / CS / Uberlândia - MG'\n",
      "  Expected: Engenheiro de IA\n",
      "  Got:      Outros\n",
      "FAIL: 'Engenheiro (a) de IA'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de IA\n",
      "FAIL: 'Engenheiro (a) de IA'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de IA\n",
      "FAIL: 'Engenheiro (a) de IA'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de IA\n",
      "FAIL: 'Engenheiro(a) de Software (Fullstack) | IT Energy'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Pleno – Plataforma de IA'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro de Automação Industrial'\n",
      "  Expected: Engenheiro de IA\n",
      "  Got:      Outros\n",
      "FAIL: 'Engenheiro(a) de Software Frontend'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software (.NET) Jr/Pleno | Electronic Trading'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro Computação/Software'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software (.NET) | IT Equities & Derivatives'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software IT Compliance Offshore'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software (.NET/AWS) | IT Payments & Corporate'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Backend | FTS'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Pleno/Sênior'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro / Engenheira de Software Gen AI'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software | Electronic Trading'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software (.NET/AWS) | IT AM & Funds'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software (Java) | RTB'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Sênior | IT WM'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software .NET | IT Seguros e Resseguros'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Sênior | Tech Lead'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Pleno'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software | Vaga Afirmativa para Pessoas com Deficiência'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Sênior Python | IT Performance'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de software Fullstack – IT Portfolio Management (Performance)'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Node.js | Investment Products'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Pleno a Sênior | BTG Empresas'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Java | IT Seguros e Previdência'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Sênior (.NET) | IT Offshore'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Sênior (.NET) | IT Derivativos'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Sr. - Java (Consignado)'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Pleno (Node.js) | BTG Empresas'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) Software Pl. - Java (Veiculos)'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software de Pleno à Sênior (Java) | IT Offshore'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Pl. - Função (Consignado)'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Senior - Java | Consignado'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software (Java) Sênior | IT Renda Variável'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Sr. - Função'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Sênior'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro a de software sr'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro (a) de Software Sênior - Back End'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro AI'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de IA\n",
      "FAIL: 'Engenheiro de Prompt para IA'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de IA\n",
      "FAIL: 'Engenheiro de Software Backend IA'\n",
      "  Expected: Engenheiro de Software\n",
      "  Got:      Engenheiro de IA\n",
      "FAIL: 'Engenheiro (a) de Software'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro de Software Backend IA'\n",
      "  Expected: Engenheiro de Software\n",
      "  Got:      Engenheiro de IA\n",
      "FAIL: 'Engenheiro(a) de Software Especialista (Staff Engineer)'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro de inteligencia artificial senior'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de IA\n",
      "FAIL: 'Engenheiro Software Full-Stack'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Pleno'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro Software Front-End Next.js | Arquitetura e Integrações'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro (a) de Software Sênior (React)'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de software Sênior (backend Python)'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro (a) de Software .NET Pleno/ Senior'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Sênior'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Full Stack Sênior'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro (a) de Software Sênior (React)'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro a de software pleno'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro Sênior de Software / P + D (ASP.NET) - Trabalho Remoto | REF#281465'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro Sênior de Software / P + D (ASP.NET) - Trabalho Remoto | REF#281462'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro Sênior de Software / P + D (ASP.NET) - Trabalho Remoto | REF#281469'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro Sênior de Software / P + D (ASP.NET) - Trabalho Remoto | REF#281467'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro a de software senior'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro Sênior de Software / P + D (ASP.NET) - Trabalho Remoto | REF#281468'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro Sênior de Software / P + D (ASP.NET) - Trabalho Remoto | REF#281464'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Mobile Sênior (Android)'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro Sênior de Software / P + D (ASP.NET) - Trabalho Remoto'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: '[Tecnologia] Engenheiro(a) de Software Sênior (Java/Kotlin) | Vertical Reforma Tributária'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'ENGENHEIRO DE INTELIGENCIA ARTIFICIAL'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de IA\n",
      "FAIL: 'Engenheiro / Engenheira de Software Back End'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro de Desenvolvimento de Software | Industry X'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro a de software'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software com Foco em IA'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "\n",
      "Test results: 3336 passed, 76 failed\n"
     ]
    }
   ],
   "source": [
    "jobs_classified = pd.read_csv('jobs_classified.csv')\n",
    "jobs_classified_tuple = list(zip(jobs_classified['job_title'], jobs_classified['classified_job_title']))\n",
    "\n",
    "test_classifier(jobs_classified_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b626661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\\\b(data scientist|cientista de dados)\\\\b',\n",
       " '\\\\b(ml|machine learning|deep learning|llm|nlp)\\\\b',\n",
       " '(pesquisador|research).*(dados|data)',\n",
       " 'ci[êe]ncia de dados',\n",
       " '\\\\bgenai\\\\b',\n",
       " '(computer vision|visão computacional)']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROLE_PATTERNS['Cientista de Dados']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7807549a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>job_title</th>\n",
       "      <th>classified_job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>2752</td>\n",
       "      <td>Azure Data Engineer</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>3059</td>\n",
       "      <td>Blockchain Data Engineer (Senior/Lead) ID34521</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>3035</td>\n",
       "      <td>Data Engineer with PowerCenter Experience - Re...</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>1076</td>\n",
       "      <td>Engenheiro(a) de Dados (DevOps/DataOps)</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>737</td>\n",
       "      <td>Engenheiro de Dados - Trabalho Remoto | REF#25...</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>1886</td>\n",
       "      <td>Engenheiro/ Engenheira de Dados Pyspark</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>833</td>\n",
       "      <td>Engenheiro(a) de Dados</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>1911</td>\n",
       "      <td>Engenheiro de dados</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>2398</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>2893</td>\n",
       "      <td>Banco de Talentos Data Engineer</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>2428</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>3007</td>\n",
       "      <td>Data Engineer - Remote Work | REF#272153</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>2351</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>2698</td>\n",
       "      <td>Azure Data Engineer</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>2830</td>\n",
       "      <td>Azure Data Engineer</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>1475</td>\n",
       "      <td>Engenheiro de dados</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>3100</td>\n",
       "      <td>Senior Lead Data Engineer</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>1518</td>\n",
       "      <td>Engenheiro de Dados Sênior</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>973</td>\n",
       "      <td>Engenheiro de Dados Sênior</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3032</th>\n",
       "      <td>3032</td>\n",
       "      <td>Data Engineer - Databricks - Tech Lead</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                          job_title  \\\n",
       "2752        2752                                Azure Data Engineer   \n",
       "3059        3059     Blockchain Data Engineer (Senior/Lead) ID34521   \n",
       "3035        3035  Data Engineer with PowerCenter Experience - Re...   \n",
       "1076        1076            Engenheiro(a) de Dados (DevOps/DataOps)   \n",
       "737          737  Engenheiro de Dados - Trabalho Remoto | REF#25...   \n",
       "1886        1886            Engenheiro/ Engenheira de Dados Pyspark   \n",
       "833          833                             Engenheiro(a) de Dados   \n",
       "1911        1911                                Engenheiro de dados   \n",
       "2398        2398                                      Data Engineer   \n",
       "2893        2893                    Banco de Talentos Data Engineer   \n",
       "2428        2428                                      Data Engineer   \n",
       "3007        3007           Data Engineer - Remote Work | REF#272153   \n",
       "2351        2351                                      Data Engineer   \n",
       "2698        2698                                Azure Data Engineer   \n",
       "2830        2830                                Azure Data Engineer   \n",
       "1475        1475                                Engenheiro de dados   \n",
       "3100        3100                          Senior Lead Data Engineer   \n",
       "1518        1518                         Engenheiro de Dados Sênior   \n",
       "973          973                         Engenheiro de Dados Sênior   \n",
       "3032        3032             Data Engineer - Databricks - Tech Lead   \n",
       "\n",
       "     classified_job_title  \n",
       "2752  Engenheiro de Dados  \n",
       "3059  Engenheiro de Dados  \n",
       "3035  Engenheiro de Dados  \n",
       "1076  Engenheiro de Dados  \n",
       "737   Engenheiro de Dados  \n",
       "1886  Engenheiro de Dados  \n",
       "833   Engenheiro de Dados  \n",
       "1911  Engenheiro de Dados  \n",
       "2398  Engenheiro de Dados  \n",
       "2893  Engenheiro de Dados  \n",
       "2428  Engenheiro de Dados  \n",
       "3007  Engenheiro de Dados  \n",
       "2351  Engenheiro de Dados  \n",
       "2698  Engenheiro de Dados  \n",
       "2830  Engenheiro de Dados  \n",
       "1475  Engenheiro de Dados  \n",
       "3100  Engenheiro de Dados  \n",
       "1518  Engenheiro de Dados  \n",
       "973   Engenheiro de Dados  \n",
       "3032  Engenheiro de Dados  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_classified[jobs_classified['classified_job_title']=='Engenheiro de Dados'].sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c478bc94",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e3e4d7",
   "metadata": {},
   "source": [
    "# Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97150183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1944d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_locations(df: pd.DataFrame, location_col: str = 'location') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardizes location data into separate city, state, and country columns.\n",
    "    Handles cases like \"São Paulo, Brasil\" and \"Distrito Federal, Brasil\" correctly.\n",
    "    Also handles \"e Região\" patterns for state capitals.\n",
    "    \"\"\"\n",
    "    \n",
    "    df['city'] = None\n",
    "    df['state'] = None\n",
    "    df['country'] = 'Brasil'\n",
    "    \n",
    "    brazilian_states = {\n",
    "        'AC': 'Acre', 'AL': 'Alagoas', 'AP': 'Amapá', 'AM': 'Amazonas',\n",
    "        'BA': 'Bahia', 'CE': 'Ceará', 'DF': 'Distrito Federal',\n",
    "        'ES': 'Espírito Santo', 'GO': 'Goiás', 'MA': 'Maranhão',\n",
    "        'MT': 'Mato Grosso', 'MS': 'Mato Grosso do Sul',\n",
    "        'MG': 'Minas Gerais', 'PA': 'Pará', 'PB': 'Paraíba',\n",
    "        'PR': 'Paraná', 'PE': 'Pernambuco', 'PI': 'Piauí',\n",
    "        'RJ': 'Rio de Janeiro', 'RN': 'Rio Grande do Norte',\n",
    "        'RS': 'Rio Grande do Sul', 'RO': 'Rondônia',\n",
    "        'RR': 'Roraima', 'SC': 'Santa Catarina',\n",
    "        'SP': 'São Paulo', 'SE': 'Sergipe', 'TO': 'Tocantins'\n",
    "    }\n",
    "    \n",
    "    state_capitals = {\n",
    "        'Rio Branco': 'AC', 'Maceió': 'AL', 'Macapá': 'AP', 'Manaus': 'AM',\n",
    "        'Salvador': 'BA', 'Fortaleza': 'CE', 'Brasília': 'DF', 'Vitória': 'ES',\n",
    "        'Goiânia': 'GO', 'São Luís': 'MA', 'Cuiabá': 'MT', 'Campo Grande': 'MS',\n",
    "        'Belo Horizonte': 'MG', 'Belém': 'PA', 'João Pessoa': 'PB', 'Curitiba': 'PR',\n",
    "        'Recife': 'PE', 'Teresina': 'PI', 'Rio De Janeiro': 'RJ', 'Natal': 'RN',\n",
    "        'Porto Alegre': 'RS', 'Porto Velho': 'RO', 'Boa Vista': 'RR', 'Florianópolis': 'SC',\n",
    "        'São Paulo': 'SP', 'Aracaju': 'SE', 'Palmas': 'TO'\n",
    "    }\n",
    "    \n",
    "    state_mapping = {**{v: k for k, v in brazilian_states.items()}, **brazilian_states}\n",
    "    \n",
    "    state_names = set(brazilian_states.values())\n",
    "    state_abbrevs = set(brazilian_states.keys())\n",
    "    \n",
    "    def extract_location(location):\n",
    "        if pd.isna(location):\n",
    "            return (None, None, None)\n",
    "            \n",
    "        location = str(location).strip()\n",
    "\n",
    "        if location.lower() in ['brasil']:\n",
    "            return (None, None, 'Brasil')\n",
    "        \n",
    "        if location in state_names or location in state_abbrevs:\n",
    "            state_code = location if location in state_abbrevs else state_mapping.get(location)\n",
    "            return (None, state_code, 'Brasil')\n",
    "            \n",
    "        match = re.match(r'^(?P<state>[^,]+),\\s*Brasil$', location, re.IGNORECASE)\n",
    "        if match and match.group('state') in state_names:\n",
    "            state_name = match.group('state')\n",
    "            return (None, state_mapping.get(state_name), 'Brasil')\n",
    "        \n",
    "        match = re.match(r'^(?P<city>.+)\\s+e\\s+Região$', location)\n",
    "        if match:\n",
    "            city = match.group('city').strip().title()\n",
    "            state = state_capitals.get(city)\n",
    "            return (city, state, 'Brasil')\n",
    "        \n",
    "        match = re.match(r'^(?P<city>[^,]+),\\s*(?P<state>[A-Z]{2})$', location)\n",
    "        if match:\n",
    "            return (match.group('city').title(), match.group('state').upper(), 'Brasil')\n",
    "        \n",
    "        match = re.match(r'^(?P<city>[^,]+),\\s*(?P<state>.+)$', location)\n",
    "        if match:\n",
    "            state = match.group('state').strip()\n",
    "            \n",
    "            if state.lower() in ['brasil', 'brazil']:\n",
    "                city_name = match.group('city').title()\n",
    "                return (city_name, state_capitals.get(city_name), 'Brasil')\n",
    "                \n",
    "            if state in state_names or state in state_abbrevs:\n",
    "                state_code = state if state in state_abbrevs else state_mapping.get(state)\n",
    "                return (match.group('city').title(), state_code, 'Brasil')\n",
    "            \n",
    "            return (match.group('city').title(), None, 'Brasil')\n",
    "        \n",
    "        city_name = location.title()\n",
    "        if city_name in state_capitals:\n",
    "            return (city_name, state_capitals.get(city_name), 'Brasil')\n",
    "        \n",
    "        return (city_name, None, 'Brasil')\n",
    "    \n",
    "    df[['city', 'state', 'country']] = df[location_col].apply(\n",
    "        lambda x: pd.Series(extract_location(x))\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fb4c64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "brazilian_states = {\n",
    "    'AC': 'Acre', 'AL': 'Alagoas', 'AP': 'Amapá', 'AM': 'Amazonas',\n",
    "    'BA': 'Bahia', 'CE': 'Ceará', 'DF': 'Distrito Federal',\n",
    "    'ES': 'Espírito Santo', 'GO': 'Goiás', 'MA': 'Maranhão',\n",
    "    'MT': 'Mato Grosso', 'MS': 'Mato Grosso Do Sul',\n",
    "    'MG': 'Minas Gerais', 'PA': 'Pará', 'PB': 'Paraíba',\n",
    "    'PR': 'Paraná', 'PE': 'Pernambuco', 'PI': 'Piauí',\n",
    "    'RJ': 'RioDe Janeiro', 'RN': 'Rio Grande Do Norte',\n",
    "    'RS': 'Rio Grande Do Sul', 'RO': 'Rondônia',\n",
    "    'RR': 'Roraima', 'SC': 'Santa Catarina',\n",
    "    'SP': 'São Paulo', 'SE': 'Sergipe', 'TO': 'Tocantins'\n",
    "}\n",
    "\n",
    "# Brazilian state capitals mapping (capital city: state abbreviation)\n",
    "state_capitals = {\n",
    "    'Rio Branco': 'AC', 'Maceió': 'AL', 'Macapá': 'AP', 'Manaus': 'AM',\n",
    "    'Salvador': 'BA', 'Fortaleza': 'CE', 'Brasília': 'DF', 'Vitória': 'ES',\n",
    "    'Goiânia': 'GO', 'São Luís': 'MA', 'Cuiabá': 'MT', 'Campo Grande': 'MS',\n",
    "    'Belo Horizonte': 'MG', 'Belém': 'PA', 'João Pessoa': 'PB', 'Curitiba': 'PR',\n",
    "    'Recife': 'PE', 'Teresina': 'PI', 'Rio De Janeiro': 'RJ', 'Natal': 'RN',\n",
    "    'Porto Alegre': 'RS', 'Porto Velho': 'RO', 'Boa Vista': 'RR', 'Florianópolis': 'SC',\n",
    "    'São Paulo': 'SP', 'Aracaju': 'SE', 'Palmas': 'TO'\n",
    "}\n",
    "\n",
    "# Create bidirectional mapping for state names and abbreviations\n",
    "state_mapping = {**{v: k for k, v in brazilian_states.items()}, **brazilian_states}\n",
    "\n",
    "    # Set of state names (to check if a location is a state)\n",
    "state_names = set(brazilian_states.values())\n",
    "state_abbrevs = set(brazilian_states.keys())\n",
    "\n",
    "def extract_location(location):\n",
    "    if pd.isna(location):\n",
    "        return (None, None, None)\n",
    "        \n",
    "    location = str(location).strip()\n",
    "    \n",
    "    # Handle country-level or remote cases\n",
    "    if location.lower() in ['brasil', 'brazil', 'remote', 'remoto']:\n",
    "        return (None, None, 'Brasil')\n",
    "    \n",
    "    # Handle special case of \"Distrito Federal, Brasil\" and other direct state references\n",
    "    if location in state_names or location in state_abbrevs:\n",
    "        state_code = location if location in state_abbrevs else state_mapping.get(location)\n",
    "        return (None, state_code, 'Brasil')\n",
    "        \n",
    "    # Check for state directly followed by country (\"Distrito Federal, Brasil\")\n",
    "    match = re.match(r'^(?P<state>[^,]+),\\s*Brasil$', location, re.IGNORECASE)\n",
    "    if match and match.group('state') in state_names:\n",
    "        state_name = match.group('state')\n",
    "        return (None, state_mapping.get(state_name), 'Brasil')\n",
    "    \n",
    "    # Pattern for \"City e Região\" (e.g., \"São Paulo e Região\")\n",
    "    # Important: What comes with \"e Região\" is ALWAYS the city\n",
    "    match = re.match(r'^(?P<city>.+)\\s+e\\s+Região$', location)\n",
    "    if match:\n",
    "        city = match.group('city').strip().title()\n",
    "        # Get state from the capital mapping\n",
    "        state = state_capitals.get(city)\n",
    "        return (city, state, 'Brasil')\n",
    "    \n",
    "    # Pattern for \"City, ST\" (e.g., \"São Paulo, SP\")\n",
    "    match = re.match(r'^(?P<city>[^,]+),\\s*(?P<state>[A-Z]{2})$', location)\n",
    "    if match:\n",
    "        return (match.group('city').title(), match.group('state').upper(), 'Brasil')\n",
    "    \n",
    "    # Pattern for \"City, State\" (e.g., \"São Paulo, São Paulo\")\n",
    "    match = re.match(r'^(?P<city>[^,]+),\\s*(?P<state>.+)$', location)\n",
    "    if match:\n",
    "        state = match.group('state').strip()\n",
    "        \n",
    "        # Check if state is actually a country reference\n",
    "        if state.lower() in ['brasil', 'brazil']:\n",
    "            city_name = match.group('city').title()\n",
    "            # Check if city is a state capital\n",
    "            return (city_name, state_capitals.get(city_name), 'Brasil')\n",
    "            \n",
    "        # Check if the supposed state is actually a state\n",
    "        if state in state_names or state in state_abbrevs:\n",
    "            state_code = state if state in state_abbrevs else state_mapping.get(state)\n",
    "            return (match.group('city').title(), state_code, 'Brasil')\n",
    "        \n",
    "        # Otherwise assume first part is city, second part unknown\n",
    "        return (match.group('city').title(), None, 'Brasil')\n",
    "    \n",
    "    city_name = location.title()\n",
    "    # Check if the city is a state capital\n",
    "    if city_name in state_capitals:\n",
    "        return (city_name, state_capitals.get(city_name), 'Brasil')\n",
    "    \n",
    "    return (city_name, None, 'Brasil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1707c048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brasil</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location  city state country\n",
       "0   Brasil  None  None  Brasil"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_test = {'location': ['Brasil']}\n",
    "df = pd.DataFrame(dict_test)\n",
    "standardize_locations(df, 'location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb5d3029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, 'Brasil')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_location('Brasil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d9184ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_location(test_cases):\n",
    "    \"\"\"Test function to verify classifier behavior\"\"\"\n",
    "\n",
    "    failed = 0\n",
    "    for location, expected in test_cases:\n",
    "        result = extract_location(location)\n",
    "        if result != expected:\n",
    "            print(f\"FAIL: '{location}'\")\n",
    "            print(f\"  Expected: {expected}\")\n",
    "            print(f\"  Got:      {result}\")\n",
    "            failed += 1\n",
    "\n",
    "    print(f\"\\nTest results: {len(test_cases)-failed} passed, {failed} failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "870cdc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    ('São Paulo, SP', ('São Paulo', 'SP', 'Brasil')),\n",
    "    ('Brasil', (None, None, 'Brasil')),\n",
    "    ('São Paulo e Região', ('São Paulo', 'SP', 'Brasil')),\n",
    "    ('Rio de Janeiro e Região', ('Rio De Janeiro', 'RJ', 'Brasil')),\n",
    "    ('Distrito Federal, Brasil', (None, 'DF', 'Brasil'))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "80406d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test results: 5 passed, 0 failed\n"
     ]
    }
   ],
   "source": [
    "test_location(test_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d254287e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'location'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pschm\\OneDrive\\eng\\projetos\\linkedin_jobs_analysis\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'location'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m jobs = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33m../data/processed/df_jobs_classified.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m job_copy = jobs.copy()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df = \u001b[43mstandardize_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlocation\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 107\u001b[39m, in \u001b[36mstandardize_locations\u001b[39m\u001b[34m(df, location_col)\u001b[39m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (city_name, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mBrasil\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Apply the standardization\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m df[[\u001b[33m'\u001b[39m\u001b[33mcity\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcountry\u001b[39m\u001b[33m'\u001b[39m]] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlocation_col\u001b[49m\u001b[43m]\u001b[49m.apply(\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m x: pd.Series(extract_location(x))\n\u001b[32m    109\u001b[39m )\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pschm\\OneDrive\\eng\\projetos\\linkedin_jobs_analysis\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pschm\\OneDrive\\eng\\projetos\\linkedin_jobs_analysis\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'location'"
     ]
    }
   ],
   "source": [
    "jobs = pd.read_csv('../data/processed/df_jobs_classified.csv')\n",
    "job_copy = jobs.copy()\n",
    "df = standardize_locations(jobs, location_col='location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6dd00691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>work_model</th>\n",
       "      <th>keyword</th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>num_applicants</th>\n",
       "      <th>xp_level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_sectors</th>\n",
       "      <th>job_description</th>\n",
       "      <th>classified_job_title</th>\n",
       "      <th>post_date</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [job_id, work_model, keyword, scrape_date, job_title, company_name, location, num_applicants, xp_level, job_type, job_sectors, job_description, classified_job_title, post_date, city, state, country]\n",
       "Index: []"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['location'].str.contains('remoto')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e3078ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Barueri', 'São Paulo', 'Maracanaú', 'Brasília', 'Curitiba',\n",
       "       'Guará', 'Blumenau', 'Campinas', 'Fortaleza', 'Indaial',\n",
       "       'Rio de Janeiro', 'Contagem', 'Caxias do Sul', 'Mogi das Cruzes',\n",
       "       'Uberlândia', 'Porto Alegre', 'Cravinhos', 'Pereiro', 'Itajaí',\n",
       "       'Betim', 'Macaé', 'Goiânia', 'Palotina', 'Campo Grande', 'Serra',\n",
       "       'Tijucas', 'Novo Hamburgo', 'Osasco', 'Maringá', 'Cachoeirinha',\n",
       "       'Vitória', 'Mossoró', 'Sorocaba', 'Dois Irmãos', 'Arcos',\n",
       "       'Jaraguá do Sul', 'Joinville', 'Capivari', 'Várzea Grande', None,\n",
       "       'Marília', 'Aracaju', 'Pato Branco', 'Franca', 'Rio do Sul',\n",
       "       'Sumaré', 'Ibirama', 'Belo Horizonte', 'Recife', 'Manaus',\n",
       "       'Embu das Artes', 'Eldorado do Sul', 'Viçosa',\n",
       "       'São José do Rio Preto', 'Leopoldina', 'Monte Belo', 'Londrina',\n",
       "       'Salvador', 'Morrinhos', 'Vila Velha', 'Ribeirão Preto', 'Cuiabá',\n",
       "       'Florianópolis', 'Belém', 'Jundiaí', 'Santo André', 'Santa Rosa',\n",
       "       'Guarulhos', 'Matão', 'Lucas do Rio Verde', 'Ponta Grossa',\n",
       "       'Carlos Barbosa', 'Teresina', 'Naviraí', 'Paulínia', 'Tailândia',\n",
       "       'Paragominas', 'Ampére', 'Taguatinga', 'Toledo', 'Igrejinha',\n",
       "       'Garibaldi', 'Santa Cruz do Sul', 'Rio Grande', 'Nova Lima',\n",
       "       'Nova Santa Rita', 'Piracicaba', 'Santos', 'Vespasiano', 'Arujá',\n",
       "       'Cascavel', 'Lorena', 'Indaiatuba', 'Distrito Federal', 'Jacareí',\n",
       "       'São João del-Rei', 'Cabo de Santo Agostinho',\n",
       "       'São Bernardo do Campo', 'Ribeirão Grande', 'Dourados', 'Valinhos',\n",
       "       'Agudos', 'Ituiutaba', 'Alto Horizonte', 'São José dos Pinhais',\n",
       "       'Pinhais', 'São José dos Campos', 'Canoas', 'Guarapuava',\n",
       "       'Barretos', 'Bebedouro', 'Hortolândia', 'Palhoça', 'Limeira',\n",
       "       'Nova Iguaçu', 'Jaboatão dos Guararapes', 'Natal', 'São Luis',\n",
       "       'Jandira', 'Eusébio', 'Parauapebas', 'Itapevi', 'Ji-Paraná',\n",
       "       'Cambé', 'Poços de Caldas', 'Belem', 'Serra do Salitre', 'Chapecó',\n",
       "       'Barão de Cocais', 'Santa Maria do Pará', 'São Bento do Sul',\n",
       "       'Manacapuru', 'Barbacena', 'Lagoa da Prata', 'Cajamar',\n",
       "       'Gavião Peixoto', 'Colina', 'Itaperuçu', 'Rio Brilhante',\n",
       "       'Mato Dentro', 'Jaguariúna', 'Sertãozinho', 'Itabira', 'Ouroeste',\n",
       "       'Franco da Rocha', 'Olímpia', 'Ibaté', 'Canaã dos Carajás',\n",
       "       'Araxá', 'Mariana', 'Angra dos Reis', 'Itaberaí', 'Guaratinguetá',\n",
       "       'Cataguases', 'Ouro Branco', 'São Caetano do Sul', 'Corumbá',\n",
       "       'São João da Barra', 'Sergipe', 'Camaçari', 'Rio Grande do Sul',\n",
       "       'Aparecida de Goiânia', 'Cabreúva', 'Cocalinho', 'Barcarena',\n",
       "       'Candeias', 'Cruz Alta', 'Guadalupe', 'São Francisco do Conde',\n",
       "       'Ipojuca', 'Içara', 'Navegantes', 'Várzea da Palma',\n",
       "       'Balneário Camboriú', 'Concórdia', 'Americana', 'Varginha',\n",
       "       \"Sant'Ana do Livramento\", 'Niterói', 'Boa Vista',\n",
       "       'Luís Eduardo Magalhães', 'Sorriso', 'Montes Claros', 'Itajubá',\n",
       "       'São Carlos', 'Campina Grande', 'Bagé', 'Videira', 'Uruguaiana',\n",
       "       'Tapejara', 'Cunha', 'Araguaína', 'Taubaté', 'Curvelo', 'São José',\n",
       "       'São Luís', 'Juiz de Fora', 'Uberaba', 'Guaíba', 'Pedreira',\n",
       "       'Vinhedo', 'Santo Cristo', 'Engenheiro Beltrão', 'Porto Feliz',\n",
       "       'Suzano', 'Diadema', 'Montenegro', 'Cariacica',\n",
       "       \"Santa Bárbara d'Oeste\", 'Cotia', 'Linhares',\n",
       "       'Campos dos Goytacazes', 'Duque de Caxias', 'Resende', 'Caruaru',\n",
       "       'Olinda', 'Campo Largo', 'Marabá', 'Castanhal', 'Santarém',\n",
       "       'Cabedelo', 'Cachoeiro de Itapemirim', 'João Pessoa', 'Guarapari',\n",
       "       'Parnamirim', 'Petrolina', 'Feira de Santana',\n",
       "       'Vitória da Conquista', 'Caratinga', 'Brusque', 'Guaramirim',\n",
       "       'Criciúma', 'Timbó', 'Lages', 'Biguaçu', 'Tubarão', 'Porto Belo',\n",
       "       'Itapema', 'Paranaguá', 'Campina Grande do Sul', 'Colombo',\n",
       "       'Francisco Beltrão', 'Fazenda Rio Grande', 'Arapongas',\n",
       "       'Foz do Iguaçu', 'Anápolis', 'Rio Verde', 'Porto Velho', 'Viana',\n",
       "       'Araquari', 'Arapiraca', 'Maceió', 'Cabo Frio', 'Petrópolis',\n",
       "       'São Gonçalo', 'Rio das Ostras', 'Volta Redonda',\n",
       "       'Juazeiro do Norte', 'Patos de Minas', 'Lavras', 'Divinópolis',\n",
       "       'Ribeirão das Neves', 'Extrema', 'Governador Valadares',\n",
       "       'Pouso Alegre', 'Sete Lagoas', 'Ipatinga', 'Quatro Barras',\n",
       "       'Araucária', 'Itabirito', 'Rio Branco', 'Taboão da Serra',\n",
       "       'Bragança Paulista', 'Guarujá', 'Araras', 'Rio Claro',\n",
       "       'Presidente Prudente', 'Praia Grande', 'Louveira', 'Mogi Guaçu',\n",
       "       'Nova Odessa', 'Pindamonhangaba', 'Atibaia', 'Araraquara', 'Itu',\n",
       "       'Caraguatatuba', 'Ribeirão Pires', 'Araçatuba', 'Caieiras',\n",
       "       'Itapecerica da Serra', 'Mauá', 'Campo Bom', 'São Leopoldo',\n",
       "       'Ijuí', 'Gramado', 'Capão da Canoa', 'Alvorada', 'Esteio',\n",
       "       'Pelotas', 'Bento Gonçalves', 'Flores da Cunha', 'Santa Maria',\n",
       "       'Estância Velha', 'Sapucaia do Sul', 'Três Lagoas', 'Itatiba',\n",
       "       'Votorantim', 'Santana de Parnaíba', 'Bauru', 'Imperatriz',\n",
       "       'Farroupilha', 'Viamão', 'Conselheiro Lafaiete', 'Lagoa Santa',\n",
       "       'Primavera do Leste', 'Sinop', 'Álvares Machado', 'Caucaia',\n",
       "       'Rondonópolis', 'Macapá', 'Passo Fundo', 'Gaspar', 'Paraná',\n",
       "       'Minas Gerais', 'Camboriú', 'Ananindeua', 'Sarzedo',\n",
       "       'São José do Inhacorá', 'Fundão'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_copy['city'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0f4bc92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Barueri', 'São Paulo', 'Maracanaú', 'Brasília', 'Curitiba',\n",
       "       'Guará', 'Blumenau', 'Campinas', 'Fortaleza', 'Indaial',\n",
       "       'Rio De Janeiro', 'Contagem', 'Caxias Do Sul', 'Mogi Das Cruzes',\n",
       "       'Uberlândia', 'Porto Alegre', 'Cravinhos', 'Pereiro', 'Itajaí',\n",
       "       'Betim', 'Macaé', 'Goiânia', 'Palotina', 'Campo Grande', 'Serra',\n",
       "       'Tijucas', 'Novo Hamburgo', 'Osasco', 'Maringá', 'Cachoeirinha',\n",
       "       'Vitória', 'Mossoró', 'Sorocaba', 'Dois Irmãos', 'Arcos',\n",
       "       'Jaraguá Do Sul', 'Joinville', 'Capivari', 'Várzea Grande',\n",
       "       'Brasil', 'Marília', 'Aracaju', 'Pato Branco', 'Franca',\n",
       "       'Rio Do Sul', 'Sumaré', 'Ibirama', 'Belo Horizonte', 'Recife',\n",
       "       'Manaus', 'Embu Das Artes', 'Eldorado Do Sul', 'Viçosa',\n",
       "       'São José Do Rio Preto', 'Leopoldina', 'Monte Belo', 'Londrina',\n",
       "       'Salvador', 'Morrinhos', 'Vila Velha', 'Ribeirão Preto', 'Cuiabá',\n",
       "       'Florianópolis', 'Belém', 'Jundiaí', 'Santo André', 'Santa Rosa',\n",
       "       'Guarulhos', 'Matão', 'Lucas Do Rio Verde', 'Ponta Grossa',\n",
       "       'Carlos Barbosa', 'Teresina', 'Naviraí', 'Paulínia', 'Tailândia',\n",
       "       'Paragominas', 'Ampére', 'Taguatinga', 'Toledo', 'Igrejinha',\n",
       "       'Garibaldi', 'Santa Cruz Do Sul', 'Rio Grande', 'Nova Lima',\n",
       "       'Nova Santa Rita', 'Piracicaba', 'Santos', 'Vespasiano', 'Arujá',\n",
       "       'Cascavel', 'Lorena', 'Indaiatuba', 'Distrito Federal', 'Jacareí',\n",
       "       'São João Del-Rei', 'Cabo De Santo Agostinho',\n",
       "       'São Bernardo Do Campo', 'Ribeirão Grande', 'Dourados', 'Valinhos',\n",
       "       'Agudos', 'Ituiutaba', 'Alto Horizonte', 'São José Dos Pinhais',\n",
       "       'Pinhais', 'São José Dos Campos', 'Canoas', 'Guarapuava',\n",
       "       'Barretos', 'Bebedouro', 'Hortolândia', 'Palhoça', 'Limeira',\n",
       "       'Nova Iguaçu', 'Jaboatão Dos Guararapes', 'Natal', 'São Luis',\n",
       "       'Jandira', 'Eusébio', 'Parauapebas', 'Itapevi', 'Ji-Paraná',\n",
       "       'Cambé', 'Poços De Caldas', 'Belem', 'Serra Do Salitre', 'Chapecó',\n",
       "       'Barão De Cocais', 'Santa Maria Do Pará', 'São Bento Do Sul',\n",
       "       'Manacapuru', 'Barbacena', 'Lagoa Da Prata', 'Cajamar',\n",
       "       'Gavião Peixoto', 'Colina', 'Itaperuçu', 'Rio Brilhante',\n",
       "       'Mato Dentro', 'Jaguariúna', 'Sertãozinho', 'Itabira', 'Ouroeste',\n",
       "       'Franco Da Rocha', 'Olímpia', 'Ibaté', 'Canaã Dos Carajás',\n",
       "       'Araxá', 'Mariana', 'Angra Dos Reis', 'Itaberaí', 'Guaratinguetá',\n",
       "       'Cataguases', 'Ouro Branco', 'São Caetano Do Sul', 'Corumbá',\n",
       "       'São João Da Barra', 'Sergipe', 'Camaçari', 'Rio Grande Do Sul',\n",
       "       'Aparecida De Goiânia', 'Cabreúva', 'Cocalinho', 'Barcarena',\n",
       "       'Candeias', 'Cruz Alta', 'Guadalupe', 'São Francisco Do Conde',\n",
       "       'Ipojuca', 'Içara', 'Navegantes', 'Várzea Da Palma',\n",
       "       'Balneário Camboriú', 'Concórdia', 'Americana', 'Varginha',\n",
       "       \"Sant'Ana Do Livramento\", 'Niterói', 'Boa Vista',\n",
       "       'Luís Eduardo Magalhães', 'Sorriso', 'Montes Claros', 'Itajubá',\n",
       "       'São Carlos', 'Campina Grande', 'Bagé', 'Videira', 'Uruguaiana',\n",
       "       'Tapejara', 'Cunha', 'Araguaína', 'Taubaté', 'Curvelo', 'São José',\n",
       "       'São Luís', 'Juiz De Fora', 'Uberaba', 'Guaíba', 'Pedreira',\n",
       "       'Vinhedo', 'Santo Cristo', 'Engenheiro Beltrão', 'Porto Feliz',\n",
       "       'Suzano', 'Diadema', 'Montenegro', 'Cariacica',\n",
       "       \"Santa Bárbara D'Oeste\", 'Cotia', 'Linhares',\n",
       "       'Campos Dos Goytacazes', 'Duque De Caxias', 'Resende', 'Caruaru',\n",
       "       'Olinda', 'Campo Largo', 'Marabá', 'Castanhal', 'Santarém',\n",
       "       'Cabedelo', 'Cachoeiro De Itapemirim', 'João Pessoa', 'Guarapari',\n",
       "       'Parnamirim', 'Petrolina', 'Feira De Santana',\n",
       "       'Vitória Da Conquista', 'Caratinga', 'Brusque', 'Guaramirim',\n",
       "       'Criciúma', 'Timbó', 'Lages', 'Biguaçu', 'Tubarão', 'Porto Belo',\n",
       "       'Itapema', 'Paranaguá', 'Campina Grande Do Sul', 'Colombo',\n",
       "       'Francisco Beltrão', 'Fazenda Rio Grande', 'Arapongas',\n",
       "       'Foz Do Iguaçu', 'Anápolis', 'Rio Verde', 'Porto Velho', 'Viana',\n",
       "       'Araquari', 'Arapiraca', 'Maceió', 'Cabo Frio', 'Petrópolis',\n",
       "       'São Gonçalo', 'Rio Das Ostras', 'Volta Redonda',\n",
       "       'Juazeiro Do Norte', 'Patos De Minas', 'Lavras', 'Divinópolis',\n",
       "       'Ribeirão Das Neves', 'Extrema', 'Governador Valadares',\n",
       "       'Pouso Alegre', 'Sete Lagoas', 'Ipatinga', 'Quatro Barras',\n",
       "       'Araucária', 'Itabirito', 'Rio Branco', 'Taboão Da Serra',\n",
       "       'Bragança Paulista', 'Guarujá', 'Araras', 'Rio Claro',\n",
       "       'Presidente Prudente', 'Praia Grande', 'Louveira', 'Mogi Guaçu',\n",
       "       'Nova Odessa', 'Pindamonhangaba', 'Atibaia', 'Araraquara', 'Itu',\n",
       "       'Caraguatatuba', 'Ribeirão Pires', 'Araçatuba', 'Caieiras',\n",
       "       'Itapecerica Da Serra', 'Mauá', 'Campo Bom', 'São Leopoldo',\n",
       "       'Ijuí', 'Gramado', 'Capão Da Canoa', 'Alvorada', 'Esteio',\n",
       "       'Pelotas', 'Bento Gonçalves', 'Flores Da Cunha', 'Santa Maria',\n",
       "       'Estância Velha', 'Sapucaia Do Sul', 'Três Lagoas', 'Itatiba',\n",
       "       'Votorantim', 'Santana De Parnaíba', 'Bauru', 'Imperatriz',\n",
       "       'Farroupilha', 'Viamão', 'Conselheiro Lafaiete', 'Lagoa Santa',\n",
       "       'Primavera Do Leste', 'Sinop', 'Álvares Machado', 'Caucaia',\n",
       "       'Rondonópolis', 'Macapá', 'Passo Fundo', 'Gaspar', 'Paraná',\n",
       "       'Minas Gerais', 'Camboriú', 'Ananindeua', 'Sarzedo',\n",
       "       'São José Do Inhacorá', 'Fundão'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['city'].unique().sort()\n",
    "df['city'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5352c273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>São Paulo</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>São Paulo</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>São Paulo</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>RJ</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>São Paulo</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3504</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1296 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                city state country\n",
       "23         São Paulo  None  Brasil\n",
       "25         São Paulo  None  Brasil\n",
       "26         São Paulo  None  Brasil\n",
       "30    Rio de Janeiro    RJ  Brasil\n",
       "31         São Paulo  None  Brasil\n",
       "...              ...   ...     ...\n",
       "3485            None  None  Brasil\n",
       "3486            None  None  Brasil\n",
       "3490  Rio de Janeiro  None  Brasil\n",
       "3503            None  None  Brasil\n",
       "3504            None  None  Brasil\n",
       "\n",
       "[1296 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_copy[(job_copy[['city', 'state', 'country']] != df[['city', 'state', 'country']]).any(axis=1)][['city', 'state', 'country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1faea274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">job_copy</th>\n",
       "      <th colspan=\"3\" halign=\"left\">df</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>São Paulo</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3351</th>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Rio De Janeiro</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>São José dos Pinhais</td>\n",
       "      <td>PR</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>São José Dos Pinhais</td>\n",
       "      <td>PR</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Rio De Janeiro</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>São Paulo</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2027</th>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>RJ</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Rio De Janeiro</td>\n",
       "      <td>RJ</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Caxias do Sul</td>\n",
       "      <td>RS</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Caxias Do Sul</td>\n",
       "      <td>RS</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  job_copy                                  df              \n",
       "                      city state country                  city state country\n",
       "830              São Paulo  None  Brasil             São Paulo    SP  Brasil\n",
       "724                   None  None  Brasil                Brasil  None  Brasil\n",
       "3351        Rio de Janeiro  None  Brasil        Rio De Janeiro  None  Brasil\n",
       "2419  São José dos Pinhais    PR  Brasil  São José Dos Pinhais    PR  Brasil\n",
       "3399        Rio de Janeiro  None  Brasil        Rio De Janeiro  None  Brasil\n",
       "2345             São Paulo  None  Brasil             São Paulo    SP  Brasil\n",
       "2027        Rio de Janeiro    RJ  Brasil        Rio De Janeiro    RJ  Brasil\n",
       "1573                  None  None  Brasil                Brasil  None  Brasil\n",
       "1997         Caxias do Sul    RS  Brasil         Caxias Do Sul    RS  Brasil\n",
       "496                   None  None  Brasil                Brasil  None  Brasil"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (job_copy[['city', 'state', 'country']] != df[['city', 'state', 'country']])\n",
    "# Show both DataFrames side by side where they differ\n",
    "differences = pd.concat([job_copy[mask.any(axis=1)], df[mask.any(axis=1)]], axis=1, keys=['job_copy', 'df'])\n",
    "differences[[('job_copy', 'city'), ('job_copy', 'state'), ('job_copy', 'country'), ('df', 'city'), ('df', 'state'), ('df', 'country')]].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2b1c6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>work_model</th>\n",
       "      <th>keyword</th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>num_applicants</th>\n",
       "      <th>xp_level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_sectors</th>\n",
       "      <th>job_description</th>\n",
       "      <th>classified_job_title</th>\n",
       "      <th>post_date</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4219203458</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>2025-05-17</td>\n",
       "      <td>Analista de Dados e Serviço ao Cliente Junior</td>\n",
       "      <td>Cielo</td>\n",
       "      <td>Barueri, SP</td>\n",
       "      <td>177.0</td>\n",
       "      <td>Assistente</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Atividades de serviços financeiros</td>\n",
       "      <td>Job Description\\nSomos mais que uma máquina, s...</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>03-05-2025</td>\n",
       "      <td>Barueri</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4229491792</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>2025-05-17</td>\n",
       "      <td>Analista de dados de negócios</td>\n",
       "      <td>SulAmérica</td>\n",
       "      <td>São Paulo, SP</td>\n",
       "      <td>117.0</td>\n",
       "      <td>Pleno-sênior</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Seguros e previdência complementar e Serviços ...</td>\n",
       "      <td>A SulAmérica há mais de 125 anos se dedica a e...</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>16-05-2025</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4209520797</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>2025-05-17</td>\n",
       "      <td>Analista de Dados Júnior</td>\n",
       "      <td>Banco Fibra</td>\n",
       "      <td>São Paulo, SP</td>\n",
       "      <td>163.0</td>\n",
       "      <td>Não aplicável</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Bancos</td>\n",
       "      <td>Somos um Banco que trabalha na busca do melhor...</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>19-04-2025</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4201072662</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>2025-05-17</td>\n",
       "      <td>Analista de Dados - Júnior, Pleno e Sênior | R...</td>\n",
       "      <td>Capco</td>\n",
       "      <td>São Paulo, SP</td>\n",
       "      <td>112.0</td>\n",
       "      <td>Pleno-sênior</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Atividades de serviços financeiros</td>\n",
       "      <td>SOBRE A CAPCO\\nA Capco é uma consultoria globa...</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>26-04-2025</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4223039814</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>2025-05-17</td>\n",
       "      <td>Analista de Dados &amp; Analytics Pleno | Riscos e...</td>\n",
       "      <td>C6 Bank</td>\n",
       "      <td>São Paulo, SP</td>\n",
       "      <td>89.0</td>\n",
       "      <td>Assistente</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Bancos</td>\n",
       "      <td>Nossa área de Processos &amp; Controles\\nA área de...</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>10-05-2025</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500</th>\n",
       "      <td>4231053333</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>2025-05-18</td>\n",
       "      <td>Programador de Sistemas de Informação</td>\n",
       "      <td>Sebratel</td>\n",
       "      <td>Porto Alegre, RS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assistente</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Telecomunicações</td>\n",
       "      <td>DESCRIÇÃO\\nA SEBRATEL, empresa referência no s...</td>\n",
       "      <td>Outros</td>\n",
       "      <td>16-05-2025</td>\n",
       "      <td>Porto Alegre</td>\n",
       "      <td>RS</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3501</th>\n",
       "      <td>4232436842</td>\n",
       "      <td>Híbrido</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>2025-05-18</td>\n",
       "      <td>Analista de BI (Inteligência de Mercado) - MG</td>\n",
       "      <td>Drogaria Araujo S/A</td>\n",
       "      <td>Belo Horizonte, MG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pleno-sênior</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Comércio varejista</td>\n",
       "      <td>A Drogaria Araujo, a maior Rede de Varejo Farm...</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belo Horizonte</td>\n",
       "      <td>MG</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3502</th>\n",
       "      <td>4232150473</td>\n",
       "      <td>Híbrido</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>2025-05-18</td>\n",
       "      <td>Analista de bi business intelligence</td>\n",
       "      <td>Netvagas</td>\n",
       "      <td>São Paulo, SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pleno-sênior</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Fornecimento e gestão de recursos humanos</td>\n",
       "      <td>Na Connect For People, acreditamos em conectar...</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>17-05-2025</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503</th>\n",
       "      <td>4232380566</td>\n",
       "      <td>Remoto</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>2025-05-18</td>\n",
       "      <td>Analista de bi pleno</td>\n",
       "      <td>Netvagas</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assistente</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Fornecimento e gestão de recursos humanos</td>\n",
       "      <td>A FIAP é uma faculdade de tecnologia, inovação...</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>17-05-2025</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3504</th>\n",
       "      <td>4232422801</td>\n",
       "      <td>Remoto</td>\n",
       "      <td>Engenheiro de IA</td>\n",
       "      <td>2025-05-18</td>\n",
       "      <td>Engenheiro de inovacao e prototipagem</td>\n",
       "      <td>Netvagas</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assistente</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Fornecimento e gestão de recursos humanos</td>\n",
       "      <td>Conectar o mundo é o que nos move, e conectar ...</td>\n",
       "      <td>Outros</td>\n",
       "      <td>17-05-2025</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3505 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          job_id  work_model            keyword scrape_date  \\\n",
       "0     4219203458  Presencial  Analista de Dados  2025-05-17   \n",
       "1     4229491792  Presencial  Analista de Dados  2025-05-17   \n",
       "2     4209520797  Presencial  Analista de Dados  2025-05-17   \n",
       "3     4201072662  Presencial  Analista de Dados  2025-05-17   \n",
       "4     4223039814  Presencial  Analista de Dados  2025-05-17   \n",
       "...          ...         ...                ...         ...   \n",
       "3500  4231053333  Presencial     Analista de BI  2025-05-18   \n",
       "3501  4232436842     Híbrido     Analista de BI  2025-05-18   \n",
       "3502  4232150473     Híbrido     Analista de BI  2025-05-18   \n",
       "3503  4232380566      Remoto     Analista de BI  2025-05-18   \n",
       "3504  4232422801      Remoto   Engenheiro de IA  2025-05-18   \n",
       "\n",
       "                                              job_title         company_name  \\\n",
       "0         Analista de Dados e Serviço ao Cliente Junior                Cielo   \n",
       "1                         Analista de dados de negócios           SulAmérica   \n",
       "2                              Analista de Dados Júnior          Banco Fibra   \n",
       "3     Analista de Dados - Júnior, Pleno e Sênior | R...                Capco   \n",
       "4     Analista de Dados & Analytics Pleno | Riscos e...              C6 Bank   \n",
       "...                                                 ...                  ...   \n",
       "3500              Programador de Sistemas de Informação             Sebratel   \n",
       "3501      Analista de BI (Inteligência de Mercado) - MG  Drogaria Araujo S/A   \n",
       "3502               Analista de bi business intelligence             Netvagas   \n",
       "3503                               Analista de bi pleno             Netvagas   \n",
       "3504              Engenheiro de inovacao e prototipagem             Netvagas   \n",
       "\n",
       "                location  num_applicants       xp_level        job_type  \\\n",
       "0            Barueri, SP           177.0     Assistente  Tempo integral   \n",
       "1          São Paulo, SP           117.0   Pleno-sênior  Tempo integral   \n",
       "2          São Paulo, SP           163.0  Não aplicável  Tempo integral   \n",
       "3          São Paulo, SP           112.0   Pleno-sênior  Tempo integral   \n",
       "4          São Paulo, SP            89.0     Assistente  Tempo integral   \n",
       "...                  ...             ...            ...             ...   \n",
       "3500    Porto Alegre, RS             NaN     Assistente  Tempo integral   \n",
       "3501  Belo Horizonte, MG             NaN   Pleno-sênior  Tempo integral   \n",
       "3502       São Paulo, SP             NaN   Pleno-sênior  Tempo integral   \n",
       "3503              Brasil             NaN     Assistente  Tempo integral   \n",
       "3504              Brasil             NaN     Assistente  Tempo integral   \n",
       "\n",
       "                                            job_sectors  \\\n",
       "0                    Atividades de serviços financeiros   \n",
       "1     Seguros e previdência complementar e Serviços ...   \n",
       "2                                                Bancos   \n",
       "3                    Atividades de serviços financeiros   \n",
       "4                                                Bancos   \n",
       "...                                                 ...   \n",
       "3500                                   Telecomunicações   \n",
       "3501                                 Comércio varejista   \n",
       "3502          Fornecimento e gestão de recursos humanos   \n",
       "3503          Fornecimento e gestão de recursos humanos   \n",
       "3504          Fornecimento e gestão de recursos humanos   \n",
       "\n",
       "                                        job_description classified_job_title  \\\n",
       "0     Job Description\\nSomos mais que uma máquina, s...    Analista de Dados   \n",
       "1     A SulAmérica há mais de 125 anos se dedica a e...    Analista de Dados   \n",
       "2     Somos um Banco que trabalha na busca do melhor...    Analista de Dados   \n",
       "3     SOBRE A CAPCO\\nA Capco é uma consultoria globa...    Analista de Dados   \n",
       "4     Nossa área de Processos & Controles\\nA área de...    Analista de Dados   \n",
       "...                                                 ...                  ...   \n",
       "3500  DESCRIÇÃO\\nA SEBRATEL, empresa referência no s...               Outros   \n",
       "3501  A Drogaria Araujo, a maior Rede de Varejo Farm...       Analista de BI   \n",
       "3502  Na Connect For People, acreditamos em conectar...       Analista de BI   \n",
       "3503  A FIAP é uma faculdade de tecnologia, inovação...       Analista de BI   \n",
       "3504  Conectar o mundo é o que nos move, e conectar ...               Outros   \n",
       "\n",
       "       post_date            city state country  \n",
       "0     03-05-2025         Barueri    SP  Brasil  \n",
       "1     16-05-2025       São Paulo    SP  Brasil  \n",
       "2     19-04-2025       São Paulo    SP  Brasil  \n",
       "3     26-04-2025       São Paulo    SP  Brasil  \n",
       "4     10-05-2025       São Paulo    SP  Brasil  \n",
       "...          ...             ...   ...     ...  \n",
       "3500  16-05-2025    Porto Alegre    RS  Brasil  \n",
       "3501         NaN  Belo Horizonte    MG  Brasil  \n",
       "3502  17-05-2025       São Paulo    SP  Brasil  \n",
       "3503  17-05-2025          Brasil  None  Brasil  \n",
       "3504  17-05-2025          Brasil  None  Brasil  \n",
       "\n",
       "[3505 rows x 17 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
