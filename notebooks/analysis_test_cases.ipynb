{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5969dbdc",
   "metadata": {},
   "source": [
    "# Skill extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8c850aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Get the project root directory (e.g., linkedin_jobs_analysis/)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add project root to sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from src.utils.logger import setup_logging\n",
    "from src.analysis.extracting_skills_list import SkillExtractor\n",
    "\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd8d2e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "STANDARD_SKILL_MAP = {\n",
    "    'Solução de problemas': [\n",
    "        r'\\b(solu[cç][ãa]o de problemas|problem solving)\\b',\n",
    "        r'\\b(resolu[cç][ãa]o|solu[cç][ãa]o)\\b.*\\b(problema|problem)\\b'\n",
    "    ],\n",
    "    'Pensamento crítico': [\n",
    "        r'\\b(critical thinking|pensamento cr[ií]tico)\\b'\n",
    "    ],\n",
    "    'Inteligência Artificial': [\n",
    "        r'\\b(ia|ai|intelig[êe]ncia artificial|artificial intelligence)\\b',\n",
    "        r'(?!.*\\b(?:air|aide|caixa|main)\\b)\\b(ia|ai)\\b',  # Avoid false matches\n",
    "        r'\\b(?:chatbot|llm|generative ai)\\b'\n",
    "    ],\n",
    "    'Machine Learning': [\n",
    "        r'\\b(machine learning|aprendizado de m[aá]quina|ml\\b)\\b',\n",
    "        r'\\b(?:modelos?|algoritmos?)\\b.*\\b(?:aprendizado|machine learning)\\b'\n",
    "    ],\n",
    "    'Cloud': [\n",
    "        r'\\b(cloud|nuvem|computa[cç][ãa]o em nuvem|cloud computing)\\b',\n",
    "        r'\\b(?:gcp|azure|aws)\\b.*\\b(?:cloud|nuvem)\\b'\n",
    "    ],\n",
    "    'NLP': [\n",
    "        r'\\b(natural language processing|processamento de linguagem natural|pln|nlp)\\b',\n",
    "        r'\\b(?:texto|linguagem)\\b.*\\b(?:processamento|analysis)\\b'\n",
    "    ],\n",
    "    'Visão computacional': [\n",
    "        r'\\b(vis[aã]o computacional|computer vision|cv\\b)\\b'\n",
    "    ],\n",
    "    'Feature engineering': [\n",
    "        r'\\bfeature engineering\\b',\n",
    "        r'\\b(engenharia|constru[cç][ãa]o)\\b.*\\b(features?|caracter[ií]sticas?)\\b'\n",
    "    ],\n",
    "    'Visualização de dados': [\n",
    "        r'\\b(data visualization|visualiza[cç][ãa]o de dados)\\b',\n",
    "        r'\\b(tableau|power ?bi|looker|metabase)\\b'\n",
    "    ],\n",
    "    'Programação': [\n",
    "        r'\\b(programa[cç][ãa]o|coding|desenvolvimento)\\b(?!.*\\b(?:sql|etl)\\b)'\n",
    "    ],\n",
    "    'GCP': [\n",
    "        r'\\bgcp\\b',\n",
    "        r'\\bgoogle cloud\\b'\n",
    "    ],\n",
    "    'Excel': [\n",
    "        r'\\bexcel\\b',\n",
    "        r'\\bmicrosoft excel\\b'\n",
    "    ],\n",
    "    'Tableau': [\n",
    "        r'\\btableau\\b'\n",
    "    ],\n",
    "    'Adaptabilidade': [\n",
    "        r'\\badaptabilidade\\b',\n",
    "        r'\\b(flexibilidade|adaptability)\\b'\n",
    "    ],\n",
    "    'Azure': [\n",
    "        r'\\bazure\\b',\n",
    "        r'\\bmicrosoft azure\\b'\n",
    "    ],\n",
    "    'Estatística': [\n",
    "        r'\\b(estat[ií]stica|statistics)\\b',\n",
    "        r'\\b(an[aá]lise|analysis)\\b.*\\b(estat[ií]stica|statistical)\\b'\n",
    "    ],\n",
    "    'R': [\n",
    "        r'\\br\\b(?!.*\\b(?:python|sql)\\b)'  # Avoid matching parts of other words\n",
    "    ],\n",
    "    'Trabalho em equipe': [\n",
    "        r'\\b(trabalho em equipe|teamwork)\\b'\n",
    "    ],\n",
    "    'Limpeza de dados': [\n",
    "        r'\\b(limpeza de dados|data cleaning)\\b',\n",
    "        r'\\b(cleaning|limpeza)\\b.*\\b(data|dados)\\b'\n",
    "    ],\n",
    "    'Arquitetura de dados': [\n",
    "        r'\\b(arquitetura de dados|data architecture)\\b'\n",
    "    ],\n",
    "    'Séries temporais': [\n",
    "        r'\\b(s[ée]ries? temporais|time series)\\b'\n",
    "    ],\n",
    "    'BI': [\n",
    "        r'\\b(business intelligence|intelig[êe]ncia de neg[óo]cios|bi\\b)\\b',\n",
    "        r'\\b(?:dashboard|relat[óo]rios?)\\b.*\\b(?:bi|business intelligence)\\b'\n",
    "    ],\n",
    "    'Python': [\n",
    "        r'\\bpython\\b(?!.*\\b(?:spark|sql)\\b)'\n",
    "    ],\n",
    "    'Teste A/B': [\n",
    "        r'\\ba\\/b\\b',\n",
    "        r'\\b(?:teste|test)\\b.*\\b(?:a\\/b|ab)\\b'\n",
    "    ],\n",
    "    'ETL': [\n",
    "        r'\\betl\\b',\n",
    "        r'\\b(extract|transform|load)\\b'\n",
    "    ],\n",
    "    'Aprendizado por reforço': [\n",
    "        r'\\b(reinforcement learning|aprendizado por refor[cç]o)\\b'\n",
    "    ],\n",
    "    'PostgreSQL': [\n",
    "        r'\\bpostgre?s?ql\\b'\n",
    "    ],\n",
    "    'Redes neurais': [\n",
    "        r'\\b(redes neurais|neural networks)\\b'\n",
    "    ],\n",
    "    'NoSQL': [\n",
    "        r'\\bnosql\\b'\n",
    "    ],\n",
    "    'Airflow': [\n",
    "        r'\\bairflow\\b'\n",
    "    ],\n",
    "    'Comunicação': [\n",
    "        r'\\bcomunica[cç][ãa]o\\b',\n",
    "        r'\\b(communication|comunica[cç][ãa]o)\\b.*\\b(?:t[ée]cnica|skills)\\b'\n",
    "    ],\n",
    "    'Tensorflow': [\n",
    "        r'\\btensorflow\\b',\n",
    "        r'\\btf\\b'\n",
    "    ],\n",
    "    'Data Warehouse': [\n",
    "        r'\\b(data warehouse|datalake|data lake)\\b'\n",
    "    ],\n",
    "    'Kubernetes': [\n",
    "        r'\\bkubernetes\\b',\n",
    "        r'\\bk8s\\b'\n",
    "    ],\n",
    "    'Pipeline': [\n",
    "        r'\\b(pipeline|data pipeline)\\b'\n",
    "    ],\n",
    "    'Governança de dados': [\n",
    "        r'\\b(governan[cç]a de dados|data governance)\\b'\n",
    "    ],\n",
    "    'Hadoop': [\n",
    "        r'\\bhadoop\\b'\n",
    "    ],\n",
    "    'Manipulação de dados': [\n",
    "        r'\\b(data wrangling|manipula[cç][ãa]o de dados)\\b'\n",
    "    ],\n",
    "    'Qualidade dos dados': [\n",
    "        r'\\b(data quality|qualidade dos dados)\\b'\n",
    "    ],\n",
    "    'PyTorch': [\n",
    "        r'\\bpytorch\\b'\n",
    "    ],\n",
    "    'MySQL': [\n",
    "        r'\\bmysql\\b'\n",
    "    ],\n",
    "    'Análise de negócios': [\n",
    "        r'\\b(business analytics|an[aá]lise de neg[óo]cios)\\b'\n",
    "    ],\n",
    "    'Deep Learning': [\n",
    "        r'\\b(deep learning|aprendizado profundo)\\b'\n",
    "    ],\n",
    "    'Big Data': [\n",
    "        r'\\bbig ?data\\b'\n",
    "    ],\n",
    "    'Data storytelling': [\n",
    "        r'\\b(data storytelling|storytelling)\\b'\n",
    "    ],\n",
    "    'Mineração de dados': [\n",
    "        r'\\b(minera[cç][ãa]o de dados|data mining)\\b'\n",
    "    ],\n",
    "    'SQL': [\n",
    "        r'\\bsql\\b(?!.*\\b(?:server|mysql)\\b)'\n",
    "    ],\n",
    "    'Power BI': [\n",
    "        r'\\bpower ?bi\\b'\n",
    "    ],\n",
    "    'Spark': [\n",
    "        r'\\bspark\\b',\n",
    "        r'\\bpyspark\\b'\n",
    "    ],\n",
    "    'API': [\n",
    "        r'\\bapi\\b(?!.*\\b(?:google|azure)\\b)'\n",
    "    ],\n",
    "    'Scikit-learn': [\n",
    "        r'\\bscikit[-\\s]?learn\\b'\n",
    "    ],\n",
    "    'Pandas': [\n",
    "        r'\\bpandas\\b(?!.*\\b(?:aws|animal)\\b)'\n",
    "    ],\n",
    "    'Docker': [\n",
    "        r'\\bdocker\\b'\n",
    "    ],\n",
    "    'AWS': [\n",
    "        r'\\baws\\b',\n",
    "        r'\\bamazon web services\\b'\n",
    "    ],\n",
    "    'MATLAB': [\n",
    "        r'\\bmatlab\\b'\n",
    "    ],\n",
    "    'SQL Server': [\n",
    "        r'\\bsql server\\b'\n",
    "    ],\n",
    "    'NumPy': [\n",
    "        r'\\bnumpy\\b'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47d60fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_skill_extractor(test_cases = [\n",
    "        (\n",
    "            \"Precisamos de um profissional com experiência em Python e SQL.\",\n",
    "            ['Python', 'SQL']\n",
    "        ),\n",
    "        (\n",
    "            \"Conhecimento em Machine Learning (ML) e PowerBI é essencial.\",\n",
    "            ['Machine Learning', 'Power BI']\n",
    "        ),\n",
    "        (\n",
    "            \"Domínio de AWS, Azure e GCP para cloud computing.\",\n",
    "            ['Cloud']\n",
    "        ),\n",
    "        (\n",
    "            \"Experiência com PySpark e Spark para processamento de dados.\",\n",
    "            ['spark', 'pyspark']  # Not in standard map\n",
    "        ),\n",
    "        (\n",
    "            \"Habilidade em Excel avançado e análise de dados.\",\n",
    "            ['excel']\n",
    "        ),\n",
    "        (\n",
    "            \"Conhecimento em Airflow para orquestração de pipelines.\",\n",
    "            ['airflow']\n",
    "        ),\n",
    "        (\n",
    "            \"Não há requisitos técnicos específicos para esta vaga.\",\n",
    "            []\n",
    "        ),\n",
    "        (\n",
    "            \"Necessário conhecimento em Python e pandas para análise de dados.\",\n",
    "            ['Python', 'pandas']\n",
    "        ),\n",
    "        (\n",
    "            \"A palavra 'excelente' não deve ser confundida com Excel.\",\n",
    "            []\n",
    "        ),\n",
    "        (\n",
    "            \"MLOps e Machine Learning são importantes para a vaga.\",\n",
    "            ['Machine Learning']  # Assuming MLOps isn't in our test skills\n",
    "        )\n",
    "    ]):\n",
    "    \"\"\"Test function for SkillExtractor with various edge cases\"\"\"\n",
    "    # Sample skill list and mapping\n",
    "    test_skills = [\n",
    "        \"python\", \"sql\", \"machine learning\", \"pandas\", \n",
    "        \"power bi\", \"tableau\", \"aws\", \"azure\", \"gcp\",\n",
    "        \"spark\", \"pyspark\", \"airflow\", \"excel\"\n",
    "    ]\n",
    "    \n",
    "    test_skill_map = {\n",
    "        'Python': ['python', 'python3'],\n",
    "        'SQL': ['sql', 'structured query language'],\n",
    "        'Machine Learning': ['machine learning', 'ml', 'aprendizado de máquina'],\n",
    "        'Power BI': ['power bi', 'powerbi'],\n",
    "        'Cloud': ['aws', 'azure', 'gcp', 'cloud computing']\n",
    "    }\n",
    "\n",
    "    # Initialize extractor\n",
    "    extractor = SkillExtractor(skill_list=test_skills, standard_skill_map=test_skill_map)\n",
    "\n",
    "\n",
    "    failed = 0\n",
    "    for i, (text, expected) in enumerate(test_cases, 1):\n",
    "        try:\n",
    "            result = extractor.extract_skills(text)\n",
    "            # Convert both to sets for unordered comparison\n",
    "            result_set = set(result)\n",
    "            expected_set = set(expected)\n",
    "            \n",
    "            if result_set != expected_set:\n",
    "                print(f\"\\nFAIL Case {i}: '{text}'\")\n",
    "                print(f\"  Expected: {sorted(expected)}\")\n",
    "                print(f\"  Got:      {sorted(result)}\")\n",
    "                print(f\"  Missing:  {sorted(expected_set - result_set)}\")\n",
    "                print(f\"  Extra:    {sorted(result_set - expected_set)}\")\n",
    "                failed += 1\n",
    "            else:\n",
    "                print(f\"PASS Case {i}: '{text}' => {result}\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR Case {i}: Failed to process - {str(e)}\")\n",
    "            failed += 1\n",
    "\n",
    "    print(f\"\\nTest Results: {len(test_cases)-failed} passed, {failed} failed\")\n",
    "    return failed == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c3d5455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 13:44:28,783 - src.analysis.extracting_skills_list - SUCCESS - Successfully loaded spaCy model: pt_core_news_lg\n",
      "2025-05-18 13:44:28,785 - src.analysis.extracting_skills_list - INFO - Prepared matcher with 13 skill patterns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASS Case 1: 'Precisamos de um profissional com experiência em Python e SQL.' => ['Python', 'SQL']\n",
      "\n",
      "FAIL Case 2: 'Conhecimento em Machine Learning (ML) e PowerBI é essencial.'\n",
      "  Expected: ['Machine Learning', 'Power BI']\n",
      "  Got:      ['Machine Learning']\n",
      "  Missing:  ['Power BI']\n",
      "  Extra:    []\n",
      "PASS Case 3: 'Domínio de AWS, Azure e GCP para cloud computing.' => ['Cloud']\n",
      "PASS Case 4: 'Experiência com PySpark e Spark para processamento de dados.' => ['spark', 'pyspark']\n",
      "PASS Case 5: 'Habilidade em Excel avançado e análise de dados.' => ['excel']\n",
      "PASS Case 6: 'Conhecimento em Airflow para orquestração de pipelines.' => ['airflow']\n",
      "PASS Case 7: 'Não há requisitos técnicos específicos para esta vaga.' => []\n",
      "PASS Case 8: 'Necessário conhecimento em Python e pandas para análise de dados.' => ['pandas', 'Python']\n",
      "\n",
      "FAIL Case 9: 'A palavra 'excelente' não deve ser confundida com Excel.'\n",
      "  Expected: []\n",
      "  Got:      ['excel']\n",
      "  Missing:  []\n",
      "  Extra:    ['excel']\n",
      "PASS Case 10: 'MLOps e Machine Learning são importantes para a vaga.' => ['Machine Learning']\n",
      "\n",
      "Test Results: 8 passed, 2 failed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_skill_extractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6c0481",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766cbe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Dict, List\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbf3701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the project root directory (e.g., linkedin_jobs_analysis/)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add project root to sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Now import from src\n",
    "from config.analysis import ROLE_PATTERNS, SPECIAL_CASES\n",
    "from src.analysis.analysis_utils import test_classifier, title_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00fd560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_classifier(title: str) -> str:\n",
    "    \"\"\"\n",
    "    Classifies job titles into standardized categories using pattern matching.\n",
    "    \n",
    "    Args:\n",
    "        title: The raw job title to classify\n",
    "        \n",
    "    Returns:\n",
    "        str: The standardized job category or 'Outros' if no match found\n",
    "    \"\"\"\n",
    "    if not isinstance(title, str) or len(title.strip()) == 0:\n",
    "        return 'Outros'\n",
    "    \n",
    "    title_lower = title.lower().strip()\n",
    "    matches = []\n",
    "\n",
    "    for role, patterns in ROLE_PATTERNS.items():\n",
    "        for pattern in patterns:\n",
    "            if re.search(pattern, title_lower):\n",
    "                matches.append(role)\n",
    "                break\n",
    "\n",
    "    if matches:\n",
    "        for candidate_role in matches:\n",
    "            special_rules = SPECIAL_CASES.get(candidate_role, [])\n",
    "            for exclude_pattern, new_role in special_rules:\n",
    "                if re.search(exclude_pattern, title_lower):\n",
    "                    if new_role:\n",
    "                        return new_role\n",
    "                    matches.remove(candidate_role)\n",
    "\n",
    "        for role in ROLE_PATTERNS.keys():\n",
    "            if role in matches:\n",
    "                return role\n",
    "\n",
    "    if any(word in title_lower for word in ['dados', 'data']):\n",
    "        return 'Outros Dados'\n",
    "\n",
    "    return 'Outros'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d8314b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Analista de Dados'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_classifier('Analista de dados e automação com IA - Pleno\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e99dfcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAIL: 'Analista de dados e automação com IA - Pleno'\n",
      "  Expected: Engenheiro de IA\n",
      "  Got:      Analista de Dados\n",
      "FAIL: 'Engenheiro (a) de IA'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de IA\n",
      "FAIL: 'Engenheiro (a) de Automação Sr / CS / Uberlândia - MG'\n",
      "  Expected: Engenheiro de IA\n",
      "  Got:      Outros\n",
      "FAIL: 'Engenheiro (a) de IA'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de IA\n",
      "FAIL: 'Engenheiro (a) de IA'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de IA\n",
      "FAIL: 'Engenheiro (a) de IA'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de IA\n",
      "FAIL: 'Engenheiro(a) de Software (Fullstack) | IT Energy'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Pleno – Plataforma de IA'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro de Automação Industrial'\n",
      "  Expected: Engenheiro de IA\n",
      "  Got:      Outros\n",
      "FAIL: 'Engenheiro(a) de Software Frontend'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software (.NET) Jr/Pleno | Electronic Trading'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro Computação/Software'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software (.NET) | IT Equities & Derivatives'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software IT Compliance Offshore'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software (.NET/AWS) | IT Payments & Corporate'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Backend | FTS'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Pleno/Sênior'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro / Engenheira de Software Gen AI'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software | Electronic Trading'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software (.NET/AWS) | IT AM & Funds'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software (Java) | RTB'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Sênior | IT WM'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software .NET | IT Seguros e Resseguros'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Sênior | Tech Lead'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Pleno'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software | Vaga Afirmativa para Pessoas com Deficiência'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Sênior Python | IT Performance'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de software Fullstack – IT Portfolio Management (Performance)'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Node.js | Investment Products'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Pleno a Sênior | BTG Empresas'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Java | IT Seguros e Previdência'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Sênior (.NET) | IT Offshore'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Sênior (.NET) | IT Derivativos'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Sr. - Java (Consignado)'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Pleno (Node.js) | BTG Empresas'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) Software Pl. - Java (Veiculos)'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software de Pleno à Sênior (Java) | IT Offshore'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Pl. - Função (Consignado)'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Senior - Java | Consignado'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software (Java) Sênior | IT Renda Variável'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Sr. - Função'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Sênior'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro a de software sr'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro (a) de Software Sênior - Back End'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro AI'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de IA\n",
      "FAIL: 'Engenheiro de Prompt para IA'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de IA\n",
      "FAIL: 'Engenheiro de Software Backend IA'\n",
      "  Expected: Engenheiro de Software\n",
      "  Got:      Engenheiro de IA\n",
      "FAIL: 'Engenheiro (a) de Software'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro de Software Backend IA'\n",
      "  Expected: Engenheiro de Software\n",
      "  Got:      Engenheiro de IA\n",
      "FAIL: 'Engenheiro(a) de Software Especialista (Staff Engineer)'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro de inteligencia artificial senior'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de IA\n",
      "FAIL: 'Engenheiro Software Full-Stack'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Pleno'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro Software Front-End Next.js | Arquitetura e Integrações'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro (a) de Software Sênior (React)'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de software Sênior (backend Python)'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro (a) de Software .NET Pleno/ Senior'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Sênior'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Full Stack Sênior'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro (a) de Software Sênior (React)'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro a de software pleno'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro Sênior de Software / P + D (ASP.NET) - Trabalho Remoto | REF#281465'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro Sênior de Software / P + D (ASP.NET) - Trabalho Remoto | REF#281462'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro Sênior de Software / P + D (ASP.NET) - Trabalho Remoto | REF#281469'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro Sênior de Software / P + D (ASP.NET) - Trabalho Remoto | REF#281467'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro a de software senior'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro Sênior de Software / P + D (ASP.NET) - Trabalho Remoto | REF#281468'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro Sênior de Software / P + D (ASP.NET) - Trabalho Remoto | REF#281464'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software Mobile Sênior (Android)'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro Sênior de Software / P + D (ASP.NET) - Trabalho Remoto'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: '[Tecnologia] Engenheiro(a) de Software Sênior (Java/Kotlin) | Vertical Reforma Tributária'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'ENGENHEIRO DE INTELIGENCIA ARTIFICIAL'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de IA\n",
      "FAIL: 'Engenheiro / Engenheira de Software Back End'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro de Desenvolvimento de Software | Industry X'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro a de software'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "FAIL: 'Engenheiro(a) de Software com Foco em IA'\n",
      "  Expected: Outros\n",
      "  Got:      Engenheiro de Software\n",
      "\n",
      "Test results: 3336 passed, 76 failed\n"
     ]
    }
   ],
   "source": [
    "jobs_classified = pd.read_csv('jobs_classified.csv')\n",
    "jobs_classified_tuple = list(zip(jobs_classified['job_title'], jobs_classified['classified_job_title']))\n",
    "\n",
    "test_classifier(jobs_classified_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b626661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\\\b(data scientist|cientista de dados)\\\\b',\n",
       " '\\\\b(ml|machine learning|deep learning|llm|nlp)\\\\b',\n",
       " '(pesquisador|research).*(dados|data)',\n",
       " 'ci[êe]ncia de dados',\n",
       " '\\\\bgenai\\\\b',\n",
       " '(computer vision|visão computacional)']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROLE_PATTERNS['Cientista de Dados']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7807549a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>job_title</th>\n",
       "      <th>classified_job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>2752</td>\n",
       "      <td>Azure Data Engineer</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>3059</td>\n",
       "      <td>Blockchain Data Engineer (Senior/Lead) ID34521</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>3035</td>\n",
       "      <td>Data Engineer with PowerCenter Experience - Re...</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>1076</td>\n",
       "      <td>Engenheiro(a) de Dados (DevOps/DataOps)</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>737</td>\n",
       "      <td>Engenheiro de Dados - Trabalho Remoto | REF#25...</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>1886</td>\n",
       "      <td>Engenheiro/ Engenheira de Dados Pyspark</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>833</td>\n",
       "      <td>Engenheiro(a) de Dados</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>1911</td>\n",
       "      <td>Engenheiro de dados</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>2398</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>2893</td>\n",
       "      <td>Banco de Talentos Data Engineer</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>2428</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>3007</td>\n",
       "      <td>Data Engineer - Remote Work | REF#272153</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>2351</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>2698</td>\n",
       "      <td>Azure Data Engineer</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>2830</td>\n",
       "      <td>Azure Data Engineer</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>1475</td>\n",
       "      <td>Engenheiro de dados</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>3100</td>\n",
       "      <td>Senior Lead Data Engineer</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>1518</td>\n",
       "      <td>Engenheiro de Dados Sênior</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>973</td>\n",
       "      <td>Engenheiro de Dados Sênior</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3032</th>\n",
       "      <td>3032</td>\n",
       "      <td>Data Engineer - Databricks - Tech Lead</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                          job_title  \\\n",
       "2752        2752                                Azure Data Engineer   \n",
       "3059        3059     Blockchain Data Engineer (Senior/Lead) ID34521   \n",
       "3035        3035  Data Engineer with PowerCenter Experience - Re...   \n",
       "1076        1076            Engenheiro(a) de Dados (DevOps/DataOps)   \n",
       "737          737  Engenheiro de Dados - Trabalho Remoto | REF#25...   \n",
       "1886        1886            Engenheiro/ Engenheira de Dados Pyspark   \n",
       "833          833                             Engenheiro(a) de Dados   \n",
       "1911        1911                                Engenheiro de dados   \n",
       "2398        2398                                      Data Engineer   \n",
       "2893        2893                    Banco de Talentos Data Engineer   \n",
       "2428        2428                                      Data Engineer   \n",
       "3007        3007           Data Engineer - Remote Work | REF#272153   \n",
       "2351        2351                                      Data Engineer   \n",
       "2698        2698                                Azure Data Engineer   \n",
       "2830        2830                                Azure Data Engineer   \n",
       "1475        1475                                Engenheiro de dados   \n",
       "3100        3100                          Senior Lead Data Engineer   \n",
       "1518        1518                         Engenheiro de Dados Sênior   \n",
       "973          973                         Engenheiro de Dados Sênior   \n",
       "3032        3032             Data Engineer - Databricks - Tech Lead   \n",
       "\n",
       "     classified_job_title  \n",
       "2752  Engenheiro de Dados  \n",
       "3059  Engenheiro de Dados  \n",
       "3035  Engenheiro de Dados  \n",
       "1076  Engenheiro de Dados  \n",
       "737   Engenheiro de Dados  \n",
       "1886  Engenheiro de Dados  \n",
       "833   Engenheiro de Dados  \n",
       "1911  Engenheiro de Dados  \n",
       "2398  Engenheiro de Dados  \n",
       "2893  Engenheiro de Dados  \n",
       "2428  Engenheiro de Dados  \n",
       "3007  Engenheiro de Dados  \n",
       "2351  Engenheiro de Dados  \n",
       "2698  Engenheiro de Dados  \n",
       "2830  Engenheiro de Dados  \n",
       "1475  Engenheiro de Dados  \n",
       "3100  Engenheiro de Dados  \n",
       "1518  Engenheiro de Dados  \n",
       "973   Engenheiro de Dados  \n",
       "3032  Engenheiro de Dados  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_classified[jobs_classified['classified_job_title']=='Engenheiro de Dados'].sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c478bc94",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e3e4d7",
   "metadata": {},
   "source": [
    "# Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4edaf664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a184953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_locations(df: pd.DataFrame, location_col: str = 'location') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardizes location data into separate city, state, and country columns.\n",
    "    Handles cases like \"São Paulo, Brasil\" correctly.\n",
    "    \"\"\"\n",
    "    \n",
    "    df['city'] = None\n",
    "    df['state'] = None\n",
    "    df['country'] = 'Brasil'\n",
    "    \n",
    "    state_mapping = {\n",
    "        'AC': 'Acre', 'AL': 'Alagoas', 'AP': 'Amapá', 'AM': 'Amazonas',\n",
    "        'BA': 'Bahia', 'CE': 'Ceará', 'DF': 'Distrito Federal',\n",
    "        'ES': 'Espírito Santo', 'GO': 'Goiás', 'MA': 'Maranhão',\n",
    "        'MT': 'Mato Grosso', 'MS': 'Mato Grosso do Sul',\n",
    "        'MG': 'Minas Gerais', 'PA': 'Pará', 'PB': 'Paraíba',\n",
    "        'PR': 'Paraná', 'PE': 'Pernambuco', 'PI': 'Piauí',\n",
    "        'RJ': 'Rio de Janeiro', 'RN': 'Rio Grande do Norte',\n",
    "        'RS': 'Rio Grande do Sul', 'RO': 'Rondônia',\n",
    "        'RR': 'Roraima', 'SC': 'Santa Catarina',\n",
    "        'SP': 'São Paulo', 'SE': 'Sergipe', 'TO': 'Tocantins'\n",
    "    }\n",
    "    \n",
    "    state_mapping = {**{v: k for k, v in state_mapping.items()}, **state_mapping}\n",
    "    \n",
    "    def extract_location(location):\n",
    "        if pd.isna(location):\n",
    "            return (None, None, None)\n",
    "            \n",
    "        location = str(location).strip()\n",
    "        \n",
    "        if re.search(r',\\s*Brasil$', location, flags=re.IGNORECASE):\n",
    "            city = re.sub(r',\\s*Brasil$', '', location, flags=re.IGNORECASE).strip()\n",
    "            state = None\n",
    "            for state_abbr, state_name in state_mapping.items():\n",
    "                if city.lower() == state_name.lower():\n",
    "                    state = state_abbr\n",
    "                    break\n",
    "            return (city.title(), state, 'Brasil')\n",
    "        \n",
    "        match = re.match(r'^(?P<city>[^,]+),\\s*(?P<state>[A-Z]{2})$', location)\n",
    "        if match:\n",
    "            return (match.group('city').title(), match.group('state').upper(), 'Brasil')\n",
    "        \n",
    "        match = re.match(r'^(?P<city>[^,]+),\\s*(?P<state>.+)$', location)\n",
    "        if match:\n",
    "            state = match.group('state')\n",
    "            if state.lower() in ['brasil', 'brazil']:\n",
    "                return (match.group('city').title(), None, 'Brasil')\n",
    "            state_abbr = state_mapping.get(state.title(), state)\n",
    "            return (match.group('city').title(), state_abbr, 'Brasil')\n",
    "        \n",
    "        match = re.match(r'^(?P<city>.+)\\s+e\\s+Região$', location)\n",
    "        if match:\n",
    "            city = match.group('city')\n",
    "            state = state_mapping.get(city.title(), None)\n",
    "            return (city.title(), state, 'Brasil')\n",
    "        \n",
    "        return (location.title(), state_mapping.get(location.title(), None), 'Brasil')\n",
    "    \n",
    "    df[['city', 'state', 'country']] = df[location_col].apply(\n",
    "        lambda x: pd.Series(extract_location(x))\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb5d3029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>work_model</th>\n",
       "      <th>keyword</th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>num_applicants</th>\n",
       "      <th>xp_level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_sectors</th>\n",
       "      <th>job_description</th>\n",
       "      <th>classified_job_title</th>\n",
       "      <th>post_date</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4219203458</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>2025-05-17</td>\n",
       "      <td>Analista de Dados e Serviço ao Cliente Junior</td>\n",
       "      <td>Cielo</td>\n",
       "      <td>Barueri, SP</td>\n",
       "      <td>177.0</td>\n",
       "      <td>Assistente</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Atividades de serviços financeiros</td>\n",
       "      <td>Job Description\\nSomos mais que uma máquina, s...</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>03-05-2025</td>\n",
       "      <td>Barueri</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4229491792</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>2025-05-17</td>\n",
       "      <td>Analista de dados de negócios</td>\n",
       "      <td>SulAmérica</td>\n",
       "      <td>São Paulo, SP</td>\n",
       "      <td>117.0</td>\n",
       "      <td>Pleno-sênior</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Seguros e previdência complementar e Serviços ...</td>\n",
       "      <td>A SulAmérica há mais de 125 anos se dedica a e...</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>16-05-2025</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4209520797</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>2025-05-17</td>\n",
       "      <td>Analista de Dados Júnior</td>\n",
       "      <td>Banco Fibra</td>\n",
       "      <td>São Paulo, SP</td>\n",
       "      <td>163.0</td>\n",
       "      <td>Não aplicável</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Bancos</td>\n",
       "      <td>Somos um Banco que trabalha na busca do melhor...</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>19-04-2025</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4201072662</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>2025-05-17</td>\n",
       "      <td>Analista de Dados - Júnior, Pleno e Sênior | R...</td>\n",
       "      <td>Capco</td>\n",
       "      <td>São Paulo, SP</td>\n",
       "      <td>112.0</td>\n",
       "      <td>Pleno-sênior</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Atividades de serviços financeiros</td>\n",
       "      <td>SOBRE A CAPCO\\nA Capco é uma consultoria globa...</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>26-04-2025</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4223039814</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>2025-05-17</td>\n",
       "      <td>Analista de Dados &amp; Analytics Pleno | Riscos e...</td>\n",
       "      <td>C6 Bank</td>\n",
       "      <td>São Paulo, SP</td>\n",
       "      <td>89.0</td>\n",
       "      <td>Assistente</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Bancos</td>\n",
       "      <td>Nossa área de Processos &amp; Controles\\nA área de...</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>10-05-2025</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500</th>\n",
       "      <td>4231053333</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>2025-05-18</td>\n",
       "      <td>Programador de Sistemas de Informação</td>\n",
       "      <td>Sebratel</td>\n",
       "      <td>Porto Alegre, RS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assistente</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Telecomunicações</td>\n",
       "      <td>DESCRIÇÃO\\nA SEBRATEL, empresa referência no s...</td>\n",
       "      <td>Outros</td>\n",
       "      <td>16-05-2025</td>\n",
       "      <td>Porto Alegre</td>\n",
       "      <td>RS</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3501</th>\n",
       "      <td>4232436842</td>\n",
       "      <td>Híbrido</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>2025-05-18</td>\n",
       "      <td>Analista de BI (Inteligência de Mercado) - MG</td>\n",
       "      <td>Drogaria Araujo S/A</td>\n",
       "      <td>Belo Horizonte, MG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pleno-sênior</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Comércio varejista</td>\n",
       "      <td>A Drogaria Araujo, a maior Rede de Varejo Farm...</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belo Horizonte</td>\n",
       "      <td>MG</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3502</th>\n",
       "      <td>4232150473</td>\n",
       "      <td>Híbrido</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>2025-05-18</td>\n",
       "      <td>Analista de bi business intelligence</td>\n",
       "      <td>Netvagas</td>\n",
       "      <td>São Paulo, SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pleno-sênior</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Fornecimento e gestão de recursos humanos</td>\n",
       "      <td>Na Connect For People, acreditamos em conectar...</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>17-05-2025</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503</th>\n",
       "      <td>4232380566</td>\n",
       "      <td>Remoto</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>2025-05-18</td>\n",
       "      <td>Analista de bi pleno</td>\n",
       "      <td>Netvagas</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assistente</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Fornecimento e gestão de recursos humanos</td>\n",
       "      <td>A FIAP é uma faculdade de tecnologia, inovação...</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>17-05-2025</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3504</th>\n",
       "      <td>4232422801</td>\n",
       "      <td>Remoto</td>\n",
       "      <td>Engenheiro de IA</td>\n",
       "      <td>2025-05-18</td>\n",
       "      <td>Engenheiro de inovacao e prototipagem</td>\n",
       "      <td>Netvagas</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assistente</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Fornecimento e gestão de recursos humanos</td>\n",
       "      <td>Conectar o mundo é o que nos move, e conectar ...</td>\n",
       "      <td>Outros</td>\n",
       "      <td>17-05-2025</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3505 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          job_id  work_model            keyword scrape_date  \\\n",
       "0     4219203458  Presencial  Analista de Dados  2025-05-17   \n",
       "1     4229491792  Presencial  Analista de Dados  2025-05-17   \n",
       "2     4209520797  Presencial  Analista de Dados  2025-05-17   \n",
       "3     4201072662  Presencial  Analista de Dados  2025-05-17   \n",
       "4     4223039814  Presencial  Analista de Dados  2025-05-17   \n",
       "...          ...         ...                ...         ...   \n",
       "3500  4231053333  Presencial     Analista de BI  2025-05-18   \n",
       "3501  4232436842     Híbrido     Analista de BI  2025-05-18   \n",
       "3502  4232150473     Híbrido     Analista de BI  2025-05-18   \n",
       "3503  4232380566      Remoto     Analista de BI  2025-05-18   \n",
       "3504  4232422801      Remoto   Engenheiro de IA  2025-05-18   \n",
       "\n",
       "                                              job_title         company_name  \\\n",
       "0         Analista de Dados e Serviço ao Cliente Junior                Cielo   \n",
       "1                         Analista de dados de negócios           SulAmérica   \n",
       "2                              Analista de Dados Júnior          Banco Fibra   \n",
       "3     Analista de Dados - Júnior, Pleno e Sênior | R...                Capco   \n",
       "4     Analista de Dados & Analytics Pleno | Riscos e...              C6 Bank   \n",
       "...                                                 ...                  ...   \n",
       "3500              Programador de Sistemas de Informação             Sebratel   \n",
       "3501      Analista de BI (Inteligência de Mercado) - MG  Drogaria Araujo S/A   \n",
       "3502               Analista de bi business intelligence             Netvagas   \n",
       "3503                               Analista de bi pleno             Netvagas   \n",
       "3504              Engenheiro de inovacao e prototipagem             Netvagas   \n",
       "\n",
       "                location  num_applicants       xp_level        job_type  \\\n",
       "0            Barueri, SP           177.0     Assistente  Tempo integral   \n",
       "1          São Paulo, SP           117.0   Pleno-sênior  Tempo integral   \n",
       "2          São Paulo, SP           163.0  Não aplicável  Tempo integral   \n",
       "3          São Paulo, SP           112.0   Pleno-sênior  Tempo integral   \n",
       "4          São Paulo, SP            89.0     Assistente  Tempo integral   \n",
       "...                  ...             ...            ...             ...   \n",
       "3500    Porto Alegre, RS             NaN     Assistente  Tempo integral   \n",
       "3501  Belo Horizonte, MG             NaN   Pleno-sênior  Tempo integral   \n",
       "3502       São Paulo, SP             NaN   Pleno-sênior  Tempo integral   \n",
       "3503              Brasil             NaN     Assistente  Tempo integral   \n",
       "3504              Brasil             NaN     Assistente  Tempo integral   \n",
       "\n",
       "                                            job_sectors  \\\n",
       "0                    Atividades de serviços financeiros   \n",
       "1     Seguros e previdência complementar e Serviços ...   \n",
       "2                                                Bancos   \n",
       "3                    Atividades de serviços financeiros   \n",
       "4                                                Bancos   \n",
       "...                                                 ...   \n",
       "3500                                   Telecomunicações   \n",
       "3501                                 Comércio varejista   \n",
       "3502          Fornecimento e gestão de recursos humanos   \n",
       "3503          Fornecimento e gestão de recursos humanos   \n",
       "3504          Fornecimento e gestão de recursos humanos   \n",
       "\n",
       "                                        job_description classified_job_title  \\\n",
       "0     Job Description\\nSomos mais que uma máquina, s...    Analista de Dados   \n",
       "1     A SulAmérica há mais de 125 anos se dedica a e...    Analista de Dados   \n",
       "2     Somos um Banco que trabalha na busca do melhor...    Analista de Dados   \n",
       "3     SOBRE A CAPCO\\nA Capco é uma consultoria globa...    Analista de Dados   \n",
       "4     Nossa área de Processos & Controles\\nA área de...    Analista de Dados   \n",
       "...                                                 ...                  ...   \n",
       "3500  DESCRIÇÃO\\nA SEBRATEL, empresa referência no s...               Outros   \n",
       "3501  A Drogaria Araujo, a maior Rede de Varejo Farm...       Analista de BI   \n",
       "3502  Na Connect For People, acreditamos em conectar...       Analista de BI   \n",
       "3503  A FIAP é uma faculdade de tecnologia, inovação...       Analista de BI   \n",
       "3504  Conectar o mundo é o que nos move, e conectar ...               Outros   \n",
       "\n",
       "       post_date            city state country  \n",
       "0     03-05-2025         Barueri    SP  Brasil  \n",
       "1     16-05-2025       São Paulo    SP  Brasil  \n",
       "2     19-04-2025       São Paulo    SP  Brasil  \n",
       "3     26-04-2025       São Paulo    SP  Brasil  \n",
       "4     10-05-2025       São Paulo    SP  Brasil  \n",
       "...          ...             ...   ...     ...  \n",
       "3500  16-05-2025    Porto Alegre    RS  Brasil  \n",
       "3501         NaN  Belo Horizonte    MG  Brasil  \n",
       "3502  17-05-2025       São Paulo    SP  Brasil  \n",
       "3503  17-05-2025            None  None  Brasil  \n",
       "3504  17-05-2025            None  None  Brasil  \n",
       "\n",
       "[3505 rows x 17 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d254287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.read_csv('../data/processed/df_jobs_classified.csv')\n",
    "job_copy = jobs.copy()\n",
    "df = standardize_locations(jobs, location_col='location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6dd00691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>work_model</th>\n",
       "      <th>keyword</th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>num_applicants</th>\n",
       "      <th>xp_level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_sectors</th>\n",
       "      <th>job_description</th>\n",
       "      <th>classified_job_title</th>\n",
       "      <th>post_date</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [job_id, work_model, keyword, scrape_date, job_title, company_name, location, num_applicants, xp_level, job_type, job_sectors, job_description, classified_job_title, post_date, city, state, country]\n",
       "Index: []"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['location'].str.contains('remoto')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e3078ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Barueri', 'São Paulo', 'Maracanaú', 'Brasília', 'Curitiba',\n",
       "       'Guará', 'Blumenau', 'Campinas', 'Fortaleza', 'Indaial',\n",
       "       'Rio de Janeiro', 'Contagem', 'Caxias do Sul', 'Mogi das Cruzes',\n",
       "       'Uberlândia', 'Porto Alegre', 'Cravinhos', 'Pereiro', 'Itajaí',\n",
       "       'Betim', 'Macaé', 'Goiânia', 'Palotina', 'Campo Grande', 'Serra',\n",
       "       'Tijucas', 'Novo Hamburgo', 'Osasco', 'Maringá', 'Cachoeirinha',\n",
       "       'Vitória', 'Mossoró', 'Sorocaba', 'Dois Irmãos', 'Arcos',\n",
       "       'Jaraguá do Sul', 'Joinville', 'Capivari', 'Várzea Grande', None,\n",
       "       'Marília', 'Aracaju', 'Pato Branco', 'Franca', 'Rio do Sul',\n",
       "       'Sumaré', 'Ibirama', 'Belo Horizonte', 'Recife', 'Manaus',\n",
       "       'Embu das Artes', 'Eldorado do Sul', 'Viçosa',\n",
       "       'São José do Rio Preto', 'Leopoldina', 'Monte Belo', 'Londrina',\n",
       "       'Salvador', 'Morrinhos', 'Vila Velha', 'Ribeirão Preto', 'Cuiabá',\n",
       "       'Florianópolis', 'Belém', 'Jundiaí', 'Santo André', 'Santa Rosa',\n",
       "       'Guarulhos', 'Matão', 'Lucas do Rio Verde', 'Ponta Grossa',\n",
       "       'Carlos Barbosa', 'Teresina', 'Naviraí', 'Paulínia', 'Tailândia',\n",
       "       'Paragominas', 'Ampére', 'Taguatinga', 'Toledo', 'Igrejinha',\n",
       "       'Garibaldi', 'Santa Cruz do Sul', 'Rio Grande', 'Nova Lima',\n",
       "       'Nova Santa Rita', 'Piracicaba', 'Santos', 'Vespasiano', 'Arujá',\n",
       "       'Cascavel', 'Lorena', 'Indaiatuba', 'Distrito Federal', 'Jacareí',\n",
       "       'São João del-Rei', 'Cabo de Santo Agostinho',\n",
       "       'São Bernardo do Campo', 'Ribeirão Grande', 'Dourados', 'Valinhos',\n",
       "       'Agudos', 'Ituiutaba', 'Alto Horizonte', 'São José dos Pinhais',\n",
       "       'Pinhais', 'São José dos Campos', 'Canoas', 'Guarapuava',\n",
       "       'Barretos', 'Bebedouro', 'Hortolândia', 'Palhoça', 'Limeira',\n",
       "       'Nova Iguaçu', 'Jaboatão dos Guararapes', 'Natal', 'São Luis',\n",
       "       'Jandira', 'Eusébio', 'Parauapebas', 'Itapevi', 'Ji-Paraná',\n",
       "       'Cambé', 'Poços de Caldas', 'Belem', 'Serra do Salitre', 'Chapecó',\n",
       "       'Barão de Cocais', 'Santa Maria do Pará', 'São Bento do Sul',\n",
       "       'Manacapuru', 'Barbacena', 'Lagoa da Prata', 'Cajamar',\n",
       "       'Gavião Peixoto', 'Colina', 'Itaperuçu', 'Rio Brilhante',\n",
       "       'Mato Dentro', 'Jaguariúna', 'Sertãozinho', 'Itabira', 'Ouroeste',\n",
       "       'Franco da Rocha', 'Olímpia', 'Ibaté', 'Canaã dos Carajás',\n",
       "       'Araxá', 'Mariana', 'Angra dos Reis', 'Itaberaí', 'Guaratinguetá',\n",
       "       'Cataguases', 'Ouro Branco', 'São Caetano do Sul', 'Corumbá',\n",
       "       'São João da Barra', 'Sergipe', 'Camaçari', 'Rio Grande do Sul',\n",
       "       'Aparecida de Goiânia', 'Cabreúva', 'Cocalinho', 'Barcarena',\n",
       "       'Candeias', 'Cruz Alta', 'Guadalupe', 'São Francisco do Conde',\n",
       "       'Ipojuca', 'Içara', 'Navegantes', 'Várzea da Palma',\n",
       "       'Balneário Camboriú', 'Concórdia', 'Americana', 'Varginha',\n",
       "       \"Sant'Ana do Livramento\", 'Niterói', 'Boa Vista',\n",
       "       'Luís Eduardo Magalhães', 'Sorriso', 'Montes Claros', 'Itajubá',\n",
       "       'São Carlos', 'Campina Grande', 'Bagé', 'Videira', 'Uruguaiana',\n",
       "       'Tapejara', 'Cunha', 'Araguaína', 'Taubaté', 'Curvelo', 'São José',\n",
       "       'São Luís', 'Juiz de Fora', 'Uberaba', 'Guaíba', 'Pedreira',\n",
       "       'Vinhedo', 'Santo Cristo', 'Engenheiro Beltrão', 'Porto Feliz',\n",
       "       'Suzano', 'Diadema', 'Montenegro', 'Cariacica',\n",
       "       \"Santa Bárbara d'Oeste\", 'Cotia', 'Linhares',\n",
       "       'Campos dos Goytacazes', 'Duque de Caxias', 'Resende', 'Caruaru',\n",
       "       'Olinda', 'Campo Largo', 'Marabá', 'Castanhal', 'Santarém',\n",
       "       'Cabedelo', 'Cachoeiro de Itapemirim', 'João Pessoa', 'Guarapari',\n",
       "       'Parnamirim', 'Petrolina', 'Feira de Santana',\n",
       "       'Vitória da Conquista', 'Caratinga', 'Brusque', 'Guaramirim',\n",
       "       'Criciúma', 'Timbó', 'Lages', 'Biguaçu', 'Tubarão', 'Porto Belo',\n",
       "       'Itapema', 'Paranaguá', 'Campina Grande do Sul', 'Colombo',\n",
       "       'Francisco Beltrão', 'Fazenda Rio Grande', 'Arapongas',\n",
       "       'Foz do Iguaçu', 'Anápolis', 'Rio Verde', 'Porto Velho', 'Viana',\n",
       "       'Araquari', 'Arapiraca', 'Maceió', 'Cabo Frio', 'Petrópolis',\n",
       "       'São Gonçalo', 'Rio das Ostras', 'Volta Redonda',\n",
       "       'Juazeiro do Norte', 'Patos de Minas', 'Lavras', 'Divinópolis',\n",
       "       'Ribeirão das Neves', 'Extrema', 'Governador Valadares',\n",
       "       'Pouso Alegre', 'Sete Lagoas', 'Ipatinga', 'Quatro Barras',\n",
       "       'Araucária', 'Itabirito', 'Rio Branco', 'Taboão da Serra',\n",
       "       'Bragança Paulista', 'Guarujá', 'Araras', 'Rio Claro',\n",
       "       'Presidente Prudente', 'Praia Grande', 'Louveira', 'Mogi Guaçu',\n",
       "       'Nova Odessa', 'Pindamonhangaba', 'Atibaia', 'Araraquara', 'Itu',\n",
       "       'Caraguatatuba', 'Ribeirão Pires', 'Araçatuba', 'Caieiras',\n",
       "       'Itapecerica da Serra', 'Mauá', 'Campo Bom', 'São Leopoldo',\n",
       "       'Ijuí', 'Gramado', 'Capão da Canoa', 'Alvorada', 'Esteio',\n",
       "       'Pelotas', 'Bento Gonçalves', 'Flores da Cunha', 'Santa Maria',\n",
       "       'Estância Velha', 'Sapucaia do Sul', 'Três Lagoas', 'Itatiba',\n",
       "       'Votorantim', 'Santana de Parnaíba', 'Bauru', 'Imperatriz',\n",
       "       'Farroupilha', 'Viamão', 'Conselheiro Lafaiete', 'Lagoa Santa',\n",
       "       'Primavera do Leste', 'Sinop', 'Álvares Machado', 'Caucaia',\n",
       "       'Rondonópolis', 'Macapá', 'Passo Fundo', 'Gaspar', 'Paraná',\n",
       "       'Minas Gerais', 'Camboriú', 'Ananindeua', 'Sarzedo',\n",
       "       'São José do Inhacorá', 'Fundão'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_copy['city'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0f4bc92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Barueri', 'São Paulo', 'Maracanaú', 'Brasília', 'Curitiba',\n",
       "       'Guará', 'Blumenau', 'Campinas', 'Fortaleza', 'Indaial',\n",
       "       'Rio De Janeiro', 'Contagem', 'Caxias Do Sul', 'Mogi Das Cruzes',\n",
       "       'Uberlândia', 'Porto Alegre', 'Cravinhos', 'Pereiro', 'Itajaí',\n",
       "       'Betim', 'Macaé', 'Goiânia', 'Palotina', 'Campo Grande', 'Serra',\n",
       "       'Tijucas', 'Novo Hamburgo', 'Osasco', 'Maringá', 'Cachoeirinha',\n",
       "       'Vitória', 'Mossoró', 'Sorocaba', 'Dois Irmãos', 'Arcos',\n",
       "       'Jaraguá Do Sul', 'Joinville', 'Capivari', 'Várzea Grande',\n",
       "       'Brasil', 'Marília', 'Aracaju', 'Pato Branco', 'Franca',\n",
       "       'Rio Do Sul', 'Sumaré', 'Ibirama', 'Belo Horizonte', 'Recife',\n",
       "       'Manaus', 'Embu Das Artes', 'Eldorado Do Sul', 'Viçosa',\n",
       "       'São José Do Rio Preto', 'Leopoldina', 'Monte Belo', 'Londrina',\n",
       "       'Salvador', 'Morrinhos', 'Vila Velha', 'Ribeirão Preto', 'Cuiabá',\n",
       "       'Florianópolis', 'Belém', 'Jundiaí', 'Santo André', 'Santa Rosa',\n",
       "       'Guarulhos', 'Matão', 'Lucas Do Rio Verde', 'Ponta Grossa',\n",
       "       'Carlos Barbosa', 'Teresina', 'Naviraí', 'Paulínia', 'Tailândia',\n",
       "       'Paragominas', 'Ampére', 'Taguatinga', 'Toledo', 'Igrejinha',\n",
       "       'Garibaldi', 'Santa Cruz Do Sul', 'Rio Grande', 'Nova Lima',\n",
       "       'Nova Santa Rita', 'Piracicaba', 'Santos', 'Vespasiano', 'Arujá',\n",
       "       'Cascavel', 'Lorena', 'Indaiatuba', 'Distrito Federal', 'Jacareí',\n",
       "       'São João Del-Rei', 'Cabo De Santo Agostinho',\n",
       "       'São Bernardo Do Campo', 'Ribeirão Grande', 'Dourados', 'Valinhos',\n",
       "       'Agudos', 'Ituiutaba', 'Alto Horizonte', 'São José Dos Pinhais',\n",
       "       'Pinhais', 'São José Dos Campos', 'Canoas', 'Guarapuava',\n",
       "       'Barretos', 'Bebedouro', 'Hortolândia', 'Palhoça', 'Limeira',\n",
       "       'Nova Iguaçu', 'Jaboatão Dos Guararapes', 'Natal', 'São Luis',\n",
       "       'Jandira', 'Eusébio', 'Parauapebas', 'Itapevi', 'Ji-Paraná',\n",
       "       'Cambé', 'Poços De Caldas', 'Belem', 'Serra Do Salitre', 'Chapecó',\n",
       "       'Barão De Cocais', 'Santa Maria Do Pará', 'São Bento Do Sul',\n",
       "       'Manacapuru', 'Barbacena', 'Lagoa Da Prata', 'Cajamar',\n",
       "       'Gavião Peixoto', 'Colina', 'Itaperuçu', 'Rio Brilhante',\n",
       "       'Mato Dentro', 'Jaguariúna', 'Sertãozinho', 'Itabira', 'Ouroeste',\n",
       "       'Franco Da Rocha', 'Olímpia', 'Ibaté', 'Canaã Dos Carajás',\n",
       "       'Araxá', 'Mariana', 'Angra Dos Reis', 'Itaberaí', 'Guaratinguetá',\n",
       "       'Cataguases', 'Ouro Branco', 'São Caetano Do Sul', 'Corumbá',\n",
       "       'São João Da Barra', 'Sergipe', 'Camaçari', 'Rio Grande Do Sul',\n",
       "       'Aparecida De Goiânia', 'Cabreúva', 'Cocalinho', 'Barcarena',\n",
       "       'Candeias', 'Cruz Alta', 'Guadalupe', 'São Francisco Do Conde',\n",
       "       'Ipojuca', 'Içara', 'Navegantes', 'Várzea Da Palma',\n",
       "       'Balneário Camboriú', 'Concórdia', 'Americana', 'Varginha',\n",
       "       \"Sant'Ana Do Livramento\", 'Niterói', 'Boa Vista',\n",
       "       'Luís Eduardo Magalhães', 'Sorriso', 'Montes Claros', 'Itajubá',\n",
       "       'São Carlos', 'Campina Grande', 'Bagé', 'Videira', 'Uruguaiana',\n",
       "       'Tapejara', 'Cunha', 'Araguaína', 'Taubaté', 'Curvelo', 'São José',\n",
       "       'São Luís', 'Juiz De Fora', 'Uberaba', 'Guaíba', 'Pedreira',\n",
       "       'Vinhedo', 'Santo Cristo', 'Engenheiro Beltrão', 'Porto Feliz',\n",
       "       'Suzano', 'Diadema', 'Montenegro', 'Cariacica',\n",
       "       \"Santa Bárbara D'Oeste\", 'Cotia', 'Linhares',\n",
       "       'Campos Dos Goytacazes', 'Duque De Caxias', 'Resende', 'Caruaru',\n",
       "       'Olinda', 'Campo Largo', 'Marabá', 'Castanhal', 'Santarém',\n",
       "       'Cabedelo', 'Cachoeiro De Itapemirim', 'João Pessoa', 'Guarapari',\n",
       "       'Parnamirim', 'Petrolina', 'Feira De Santana',\n",
       "       'Vitória Da Conquista', 'Caratinga', 'Brusque', 'Guaramirim',\n",
       "       'Criciúma', 'Timbó', 'Lages', 'Biguaçu', 'Tubarão', 'Porto Belo',\n",
       "       'Itapema', 'Paranaguá', 'Campina Grande Do Sul', 'Colombo',\n",
       "       'Francisco Beltrão', 'Fazenda Rio Grande', 'Arapongas',\n",
       "       'Foz Do Iguaçu', 'Anápolis', 'Rio Verde', 'Porto Velho', 'Viana',\n",
       "       'Araquari', 'Arapiraca', 'Maceió', 'Cabo Frio', 'Petrópolis',\n",
       "       'São Gonçalo', 'Rio Das Ostras', 'Volta Redonda',\n",
       "       'Juazeiro Do Norte', 'Patos De Minas', 'Lavras', 'Divinópolis',\n",
       "       'Ribeirão Das Neves', 'Extrema', 'Governador Valadares',\n",
       "       'Pouso Alegre', 'Sete Lagoas', 'Ipatinga', 'Quatro Barras',\n",
       "       'Araucária', 'Itabirito', 'Rio Branco', 'Taboão Da Serra',\n",
       "       'Bragança Paulista', 'Guarujá', 'Araras', 'Rio Claro',\n",
       "       'Presidente Prudente', 'Praia Grande', 'Louveira', 'Mogi Guaçu',\n",
       "       'Nova Odessa', 'Pindamonhangaba', 'Atibaia', 'Araraquara', 'Itu',\n",
       "       'Caraguatatuba', 'Ribeirão Pires', 'Araçatuba', 'Caieiras',\n",
       "       'Itapecerica Da Serra', 'Mauá', 'Campo Bom', 'São Leopoldo',\n",
       "       'Ijuí', 'Gramado', 'Capão Da Canoa', 'Alvorada', 'Esteio',\n",
       "       'Pelotas', 'Bento Gonçalves', 'Flores Da Cunha', 'Santa Maria',\n",
       "       'Estância Velha', 'Sapucaia Do Sul', 'Três Lagoas', 'Itatiba',\n",
       "       'Votorantim', 'Santana De Parnaíba', 'Bauru', 'Imperatriz',\n",
       "       'Farroupilha', 'Viamão', 'Conselheiro Lafaiete', 'Lagoa Santa',\n",
       "       'Primavera Do Leste', 'Sinop', 'Álvares Machado', 'Caucaia',\n",
       "       'Rondonópolis', 'Macapá', 'Passo Fundo', 'Gaspar', 'Paraná',\n",
       "       'Minas Gerais', 'Camboriú', 'Ananindeua', 'Sarzedo',\n",
       "       'São José Do Inhacorá', 'Fundão'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['city'].unique().sort()\n",
    "df['city'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5352c273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>São Paulo</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>São Paulo</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>São Paulo</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>RJ</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>São Paulo</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3504</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1296 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                city state country\n",
       "23         São Paulo  None  Brasil\n",
       "25         São Paulo  None  Brasil\n",
       "26         São Paulo  None  Brasil\n",
       "30    Rio de Janeiro    RJ  Brasil\n",
       "31         São Paulo  None  Brasil\n",
       "...              ...   ...     ...\n",
       "3485            None  None  Brasil\n",
       "3486            None  None  Brasil\n",
       "3490  Rio de Janeiro  None  Brasil\n",
       "3503            None  None  Brasil\n",
       "3504            None  None  Brasil\n",
       "\n",
       "[1296 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_copy[(job_copy[['city', 'state', 'country']] != df[['city', 'state', 'country']]).any(axis=1)][['city', 'state', 'country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1faea274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">job_copy</th>\n",
       "      <th colspan=\"3\" halign=\"left\">df</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>São Paulo</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3351</th>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Rio De Janeiro</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>São José dos Pinhais</td>\n",
       "      <td>PR</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>São José Dos Pinhais</td>\n",
       "      <td>PR</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Rio De Janeiro</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>São Paulo</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2027</th>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>RJ</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Rio De Janeiro</td>\n",
       "      <td>RJ</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Caxias do Sul</td>\n",
       "      <td>RS</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Caxias Do Sul</td>\n",
       "      <td>RS</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  job_copy                                  df              \n",
       "                      city state country                  city state country\n",
       "830              São Paulo  None  Brasil             São Paulo    SP  Brasil\n",
       "724                   None  None  Brasil                Brasil  None  Brasil\n",
       "3351        Rio de Janeiro  None  Brasil        Rio De Janeiro  None  Brasil\n",
       "2419  São José dos Pinhais    PR  Brasil  São José Dos Pinhais    PR  Brasil\n",
       "3399        Rio de Janeiro  None  Brasil        Rio De Janeiro  None  Brasil\n",
       "2345             São Paulo  None  Brasil             São Paulo    SP  Brasil\n",
       "2027        Rio de Janeiro    RJ  Brasil        Rio De Janeiro    RJ  Brasil\n",
       "1573                  None  None  Brasil                Brasil  None  Brasil\n",
       "1997         Caxias do Sul    RS  Brasil         Caxias Do Sul    RS  Brasil\n",
       "496                   None  None  Brasil                Brasil  None  Brasil"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (job_copy[['city', 'state', 'country']] != df[['city', 'state', 'country']])\n",
    "# Show both DataFrames side by side where they differ\n",
    "differences = pd.concat([job_copy[mask.any(axis=1)], df[mask.any(axis=1)]], axis=1, keys=['job_copy', 'df'])\n",
    "differences[[('job_copy', 'city'), ('job_copy', 'state'), ('job_copy', 'country'), ('df', 'city'), ('df', 'state'), ('df', 'country')]].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2b1c6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>work_model</th>\n",
       "      <th>keyword</th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>num_applicants</th>\n",
       "      <th>xp_level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_sectors</th>\n",
       "      <th>job_description</th>\n",
       "      <th>classified_job_title</th>\n",
       "      <th>post_date</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4219203458</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>2025-05-17</td>\n",
       "      <td>Analista de Dados e Serviço ao Cliente Junior</td>\n",
       "      <td>Cielo</td>\n",
       "      <td>Barueri, SP</td>\n",
       "      <td>177.0</td>\n",
       "      <td>Assistente</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Atividades de serviços financeiros</td>\n",
       "      <td>Job Description\\nSomos mais que uma máquina, s...</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>03-05-2025</td>\n",
       "      <td>Barueri</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4229491792</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>2025-05-17</td>\n",
       "      <td>Analista de dados de negócios</td>\n",
       "      <td>SulAmérica</td>\n",
       "      <td>São Paulo, SP</td>\n",
       "      <td>117.0</td>\n",
       "      <td>Pleno-sênior</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Seguros e previdência complementar e Serviços ...</td>\n",
       "      <td>A SulAmérica há mais de 125 anos se dedica a e...</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>16-05-2025</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4209520797</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>2025-05-17</td>\n",
       "      <td>Analista de Dados Júnior</td>\n",
       "      <td>Banco Fibra</td>\n",
       "      <td>São Paulo, SP</td>\n",
       "      <td>163.0</td>\n",
       "      <td>Não aplicável</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Bancos</td>\n",
       "      <td>Somos um Banco que trabalha na busca do melhor...</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>19-04-2025</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4201072662</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>2025-05-17</td>\n",
       "      <td>Analista de Dados - Júnior, Pleno e Sênior | R...</td>\n",
       "      <td>Capco</td>\n",
       "      <td>São Paulo, SP</td>\n",
       "      <td>112.0</td>\n",
       "      <td>Pleno-sênior</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Atividades de serviços financeiros</td>\n",
       "      <td>SOBRE A CAPCO\\nA Capco é uma consultoria globa...</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>26-04-2025</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4223039814</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>2025-05-17</td>\n",
       "      <td>Analista de Dados &amp; Analytics Pleno | Riscos e...</td>\n",
       "      <td>C6 Bank</td>\n",
       "      <td>São Paulo, SP</td>\n",
       "      <td>89.0</td>\n",
       "      <td>Assistente</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Bancos</td>\n",
       "      <td>Nossa área de Processos &amp; Controles\\nA área de...</td>\n",
       "      <td>Analista de Dados</td>\n",
       "      <td>10-05-2025</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500</th>\n",
       "      <td>4231053333</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>2025-05-18</td>\n",
       "      <td>Programador de Sistemas de Informação</td>\n",
       "      <td>Sebratel</td>\n",
       "      <td>Porto Alegre, RS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assistente</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Telecomunicações</td>\n",
       "      <td>DESCRIÇÃO\\nA SEBRATEL, empresa referência no s...</td>\n",
       "      <td>Outros</td>\n",
       "      <td>16-05-2025</td>\n",
       "      <td>Porto Alegre</td>\n",
       "      <td>RS</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3501</th>\n",
       "      <td>4232436842</td>\n",
       "      <td>Híbrido</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>2025-05-18</td>\n",
       "      <td>Analista de BI (Inteligência de Mercado) - MG</td>\n",
       "      <td>Drogaria Araujo S/A</td>\n",
       "      <td>Belo Horizonte, MG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pleno-sênior</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Comércio varejista</td>\n",
       "      <td>A Drogaria Araujo, a maior Rede de Varejo Farm...</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belo Horizonte</td>\n",
       "      <td>MG</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3502</th>\n",
       "      <td>4232150473</td>\n",
       "      <td>Híbrido</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>2025-05-18</td>\n",
       "      <td>Analista de bi business intelligence</td>\n",
       "      <td>Netvagas</td>\n",
       "      <td>São Paulo, SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pleno-sênior</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Fornecimento e gestão de recursos humanos</td>\n",
       "      <td>Na Connect For People, acreditamos em conectar...</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>17-05-2025</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503</th>\n",
       "      <td>4232380566</td>\n",
       "      <td>Remoto</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>2025-05-18</td>\n",
       "      <td>Analista de bi pleno</td>\n",
       "      <td>Netvagas</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assistente</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Fornecimento e gestão de recursos humanos</td>\n",
       "      <td>A FIAP é uma faculdade de tecnologia, inovação...</td>\n",
       "      <td>Analista de BI</td>\n",
       "      <td>17-05-2025</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3504</th>\n",
       "      <td>4232422801</td>\n",
       "      <td>Remoto</td>\n",
       "      <td>Engenheiro de IA</td>\n",
       "      <td>2025-05-18</td>\n",
       "      <td>Engenheiro de inovacao e prototipagem</td>\n",
       "      <td>Netvagas</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assistente</td>\n",
       "      <td>Tempo integral</td>\n",
       "      <td>Fornecimento e gestão de recursos humanos</td>\n",
       "      <td>Conectar o mundo é o que nos move, e conectar ...</td>\n",
       "      <td>Outros</td>\n",
       "      <td>17-05-2025</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3505 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          job_id  work_model            keyword scrape_date  \\\n",
       "0     4219203458  Presencial  Analista de Dados  2025-05-17   \n",
       "1     4229491792  Presencial  Analista de Dados  2025-05-17   \n",
       "2     4209520797  Presencial  Analista de Dados  2025-05-17   \n",
       "3     4201072662  Presencial  Analista de Dados  2025-05-17   \n",
       "4     4223039814  Presencial  Analista de Dados  2025-05-17   \n",
       "...          ...         ...                ...         ...   \n",
       "3500  4231053333  Presencial     Analista de BI  2025-05-18   \n",
       "3501  4232436842     Híbrido     Analista de BI  2025-05-18   \n",
       "3502  4232150473     Híbrido     Analista de BI  2025-05-18   \n",
       "3503  4232380566      Remoto     Analista de BI  2025-05-18   \n",
       "3504  4232422801      Remoto   Engenheiro de IA  2025-05-18   \n",
       "\n",
       "                                              job_title         company_name  \\\n",
       "0         Analista de Dados e Serviço ao Cliente Junior                Cielo   \n",
       "1                         Analista de dados de negócios           SulAmérica   \n",
       "2                              Analista de Dados Júnior          Banco Fibra   \n",
       "3     Analista de Dados - Júnior, Pleno e Sênior | R...                Capco   \n",
       "4     Analista de Dados & Analytics Pleno | Riscos e...              C6 Bank   \n",
       "...                                                 ...                  ...   \n",
       "3500              Programador de Sistemas de Informação             Sebratel   \n",
       "3501      Analista de BI (Inteligência de Mercado) - MG  Drogaria Araujo S/A   \n",
       "3502               Analista de bi business intelligence             Netvagas   \n",
       "3503                               Analista de bi pleno             Netvagas   \n",
       "3504              Engenheiro de inovacao e prototipagem             Netvagas   \n",
       "\n",
       "                location  num_applicants       xp_level        job_type  \\\n",
       "0            Barueri, SP           177.0     Assistente  Tempo integral   \n",
       "1          São Paulo, SP           117.0   Pleno-sênior  Tempo integral   \n",
       "2          São Paulo, SP           163.0  Não aplicável  Tempo integral   \n",
       "3          São Paulo, SP           112.0   Pleno-sênior  Tempo integral   \n",
       "4          São Paulo, SP            89.0     Assistente  Tempo integral   \n",
       "...                  ...             ...            ...             ...   \n",
       "3500    Porto Alegre, RS             NaN     Assistente  Tempo integral   \n",
       "3501  Belo Horizonte, MG             NaN   Pleno-sênior  Tempo integral   \n",
       "3502       São Paulo, SP             NaN   Pleno-sênior  Tempo integral   \n",
       "3503              Brasil             NaN     Assistente  Tempo integral   \n",
       "3504              Brasil             NaN     Assistente  Tempo integral   \n",
       "\n",
       "                                            job_sectors  \\\n",
       "0                    Atividades de serviços financeiros   \n",
       "1     Seguros e previdência complementar e Serviços ...   \n",
       "2                                                Bancos   \n",
       "3                    Atividades de serviços financeiros   \n",
       "4                                                Bancos   \n",
       "...                                                 ...   \n",
       "3500                                   Telecomunicações   \n",
       "3501                                 Comércio varejista   \n",
       "3502          Fornecimento e gestão de recursos humanos   \n",
       "3503          Fornecimento e gestão de recursos humanos   \n",
       "3504          Fornecimento e gestão de recursos humanos   \n",
       "\n",
       "                                        job_description classified_job_title  \\\n",
       "0     Job Description\\nSomos mais que uma máquina, s...    Analista de Dados   \n",
       "1     A SulAmérica há mais de 125 anos se dedica a e...    Analista de Dados   \n",
       "2     Somos um Banco que trabalha na busca do melhor...    Analista de Dados   \n",
       "3     SOBRE A CAPCO\\nA Capco é uma consultoria globa...    Analista de Dados   \n",
       "4     Nossa área de Processos & Controles\\nA área de...    Analista de Dados   \n",
       "...                                                 ...                  ...   \n",
       "3500  DESCRIÇÃO\\nA SEBRATEL, empresa referência no s...               Outros   \n",
       "3501  A Drogaria Araujo, a maior Rede de Varejo Farm...       Analista de BI   \n",
       "3502  Na Connect For People, acreditamos em conectar...       Analista de BI   \n",
       "3503  A FIAP é uma faculdade de tecnologia, inovação...       Analista de BI   \n",
       "3504  Conectar o mundo é o que nos move, e conectar ...               Outros   \n",
       "\n",
       "       post_date            city state country  \n",
       "0     03-05-2025         Barueri    SP  Brasil  \n",
       "1     16-05-2025       São Paulo    SP  Brasil  \n",
       "2     19-04-2025       São Paulo    SP  Brasil  \n",
       "3     26-04-2025       São Paulo    SP  Brasil  \n",
       "4     10-05-2025       São Paulo    SP  Brasil  \n",
       "...          ...             ...   ...     ...  \n",
       "3500  16-05-2025    Porto Alegre    RS  Brasil  \n",
       "3501         NaN  Belo Horizonte    MG  Brasil  \n",
       "3502  17-05-2025       São Paulo    SP  Brasil  \n",
       "3503  17-05-2025          Brasil  None  Brasil  \n",
       "3504  17-05-2025          Brasil  None  Brasil  \n",
       "\n",
       "[3505 rows x 17 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
