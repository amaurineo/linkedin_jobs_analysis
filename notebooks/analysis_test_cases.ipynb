{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5969dbdc",
   "metadata": {},
   "source": [
    "# Skill extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8c850aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Get the project root directory (e.g., linkedin_jobs_analysis/)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add project root to sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from src.utils.logger import setup_logging\n",
    "from src.analysis.extracting_skills_list import SkillExtractor\n",
    "from config.analysis import STANDARD_SKILL_MAP\n",
    "\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47d60fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_skill_extractor(test_cases = [\n",
    "        (\n",
    "            \"Precisamos de um profissional com experiência em Python e SQL.\",\n",
    "            ['Python', 'SQL']\n",
    "        ),\n",
    "        (\n",
    "            \"Conhecimento em Machine Learning (ML) e PowerBI é essencial.\",\n",
    "            ['Machine Learning', 'Power BI']\n",
    "        ),\n",
    "        (\n",
    "            \"Domínio de AWS, Azure e GCP para cloud computing.\",\n",
    "            ['Cloud', 'AWS', 'Azure', 'GCP']\n",
    "        ),\n",
    "        (\n",
    "            \"Experiência com PySpark e Spark para processamento de dados.\",\n",
    "            ['Spark']\n",
    "        ),\n",
    "        (\n",
    "            \"Habilidade em Excel avançado e análise de dados.\",\n",
    "            ['Excel']\n",
    "        ),\n",
    "        (\n",
    "            \"Conhecimento em Airflow para orquestração de pipelines.\",\n",
    "            ['Airflow']\n",
    "        ),\n",
    "        (\n",
    "            \"Não há requisitos técnicos específicos para esta vaga.\",\n",
    "            []\n",
    "        ),\n",
    "        (\n",
    "            \"Necessário conhecimento em Python e pandas para análise de dados.\",\n",
    "            ['Python', 'Pandas']\n",
    "        ),\n",
    "        (\n",
    "            \"A palavra 'excelente' não deve ser confundida com 3xc3l.\",\n",
    "            []\n",
    "        ),\n",
    "        (\n",
    "            \"MLOps e Machine Learning são importantes para a vaga.\",\n",
    "            ['Machine Learning']  # Assuming MLOps isn't in our test skills\n",
    "        )\n",
    "    ]):\n",
    "    \"\"\"Test function for SkillExtractor with various edge cases\"\"\"\n",
    "\n",
    "    extractor = SkillExtractor(STANDARD_SKILL_MAP)\n",
    "    \n",
    "    passed = 0\n",
    "    failed = 0\n",
    "    failed_cases = []\n",
    "    \n",
    "    for text, expected in test_cases:\n",
    "        try:\n",
    "            result = extractor.extract_skills(text)\n",
    "            result_set = set(result)\n",
    "            expected_set = set(expected)\n",
    "            \n",
    "            # Check for missing skills\n",
    "            missing = expected_set - result_set\n",
    "            # Check for extra skills (only fail if we got completely unexpected skills)\n",
    "            extra = result_set - expected_set\n",
    "            print(extra)\n",
    "            if not missing and not extra:\n",
    "                passed += 1\n",
    "                print(f\"PASS: '{text}' -> {result}\")\n",
    "            else:\n",
    "                failed += 1\n",
    "                failed_cases.append({\n",
    "                    'text': text,\n",
    "                    'expected': expected,\n",
    "                    'got': result,\n",
    "                    'missing': list(missing),\n",
    "                    'extra': list(extra)\n",
    "                })\n",
    "                print(f\"FAIL: '{text}'\")\n",
    "                print(f\"  Expected: {expected}\")\n",
    "                print(f\"  Got:      {result}\")\n",
    "                if missing:\n",
    "                    print(f\"  Missing:  {list(missing)}\")\n",
    "                if extra:\n",
    "                    print(f\"  Extra:    {list(extra)}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            failed += 1\n",
    "            failed_cases.append({\n",
    "                'text': text,\n",
    "                'error': str(e)\n",
    "            })\n",
    "            print(f\"ERROR processing: '{text}' - {str(e)}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nTest Results: {passed} passed, {failed} failed\")\n",
    "    \n",
    "    if failed_cases:\n",
    "        print(\"\\nFailed Cases Summary:\")\n",
    "        for case in failed_cases:\n",
    "            if 'error' in case:\n",
    "                print(f\"Text: '{case['text']}'\")\n",
    "                print(f\"Error: {case['error']}\")\n",
    "            else:\n",
    "                print(f\"Text: '{case['text']}'\")\n",
    "                print(f\"Expected: {case['expected']}\")\n",
    "                print(f\"Got:      {case['got']}\")\n",
    "                if case['missing']:\n",
    "                    print(f\"Missing:  {case['missing']}\")\n",
    "                if case['extra']:\n",
    "                    print(f\"Extra:    {case['extra']}\")\n",
    "            print(\"---\")\n",
    "    \n",
    "    return {\n",
    "        'passed': passed,\n",
    "        'failed': failed,\n",
    "        'failed_cases': failed_cases,\n",
    "        'success_rate': passed / (passed + failed) if (passed + failed) > 0 else 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "157e58b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 17:30:52,946 - src.analysis.extracting_skills_list - SUCCESS - Successfully loaded spaCy model: pt_core_news_lg\n",
      "2025-05-18 17:30:52,948 - src.analysis.extracting_skills_list - INFO - Prepared regex patterns for 126 skills.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MLOps']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skills_list = [skill for synonyms in STANDARD_SKILL_MAP.values() for skill in synonyms]\n",
    "extractor = SkillExtractor(STANDARD_SKILL_MAP)\n",
    "text = 'MLOps são importantes para a vaga.'\n",
    "extractor.extract_skills(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4da6324d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 17:30:30,647 - src.analysis.extracting_skills_list - SUCCESS - Successfully loaded spaCy model: pt_core_news_lg\n",
      "2025-05-18 17:30:30,648 - src.analysis.extracting_skills_list - INFO - Prepared regex patterns for 126 skills.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "PASS: 'Precisamos de um profissional com experiência em Python e SQL.' -> ['SQL', 'Python']\n",
      "set()\n",
      "PASS: 'Conhecimento em Machine Learning (ML) e PowerBI é essencial.' -> ['Power BI', 'Machine Learning']\n",
      "set()\n",
      "PASS: 'Domínio de AWS, Azure e GCP para cloud computing.' -> ['AWS', 'GCP', 'Azure', 'Cloud']\n",
      "set()\n",
      "PASS: 'Experiência com PySpark e Spark para processamento de dados.' -> ['Spark']\n",
      "set()\n",
      "PASS: 'Habilidade em Excel avançado e análise de dados.' -> ['Excel']\n",
      "set()\n",
      "PASS: 'Conhecimento em Airflow para orquestração de pipelines.' -> ['Airflow']\n",
      "set()\n",
      "PASS: 'Não há requisitos técnicos específicos para esta vaga.' -> []\n",
      "set()\n",
      "PASS: 'Necessário conhecimento em Python e pandas para análise de dados.' -> ['Pandas', 'Python']\n",
      "set()\n",
      "PASS: 'A palavra 'excelente' não deve ser confundida com 3xc3l.' -> []\n",
      "{'MLOps'}\n",
      "FAIL: 'MLOps e Machine Learning são importantes para a vaga.'\n",
      "  Expected: ['Machine Learning']\n",
      "  Got:      ['Machine Learning', 'MLOps']\n",
      "  Extra:    ['MLOps']\n",
      "\n",
      "Test Results: 9 passed, 1 failed\n",
      "\n",
      "Failed Cases Summary:\n",
      "Text: 'MLOps e Machine Learning são importantes para a vaga.'\n",
      "Expected: ['Machine Learning']\n",
      "Got:      ['Machine Learning', 'MLOps']\n",
      "Extra:    ['MLOps']\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'passed': 9,\n",
       " 'failed': 1,\n",
       " 'failed_cases': [{'text': 'MLOps e Machine Learning são importantes para a vaga.',\n",
       "   'expected': ['Machine Learning'],\n",
       "   'got': ['Machine Learning', 'MLOps'],\n",
       "   'missing': [],\n",
       "   'extra': ['MLOps']}],\n",
       " 'success_rate': 0.9}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_skill_extractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6c0481",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b6f868",
   "metadata": {},
   "source": [
    "# Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf3701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Get the project root directory\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add project root to sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Importing from src\n",
    "from config.analysis import ROLE_PATTERNS\n",
    "from src.analysis.analysis_utils import test_classifier, title_classifier\n",
    "from src.utils.logger import setup_logging\n",
    "\n",
    "setup_logging()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d8314b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pessoa Engenheira de Dados Sr - Outros Dados: Engenheiro de Dados\n",
      "[Dados] Especialista em Análise de Dados - Outros Dados: Analista de Dados\n",
      "Artificial Intelligence Engineer - Outros: Engenheiro de IA\n",
      "Artificial Intelligence Engineer, IgniteTech (... - Outros: Engenheiro de IA\n",
      "Banco de Talentos - Eng de Dados - Júnior/Plen... - Outros Dados: Engenheiro de Dados\n",
      "Pessoa Engenheira de Dados Sênior - Outros Dados: Engenheiro de Dados\n",
      "Data Insights Analyst - Outros Dados: Analista de Dados\n"
     ]
    }
   ],
   "source": [
    "list_positions = ['Pessoa Engenheira de Dados Sr - Outros Dados', '[Dados] Especialista em Análise de Dados - Outros Dados', \n",
    "                  'Artificial Intelligence Engineer - Outros', 'Artificial Intelligence Engineer, IgniteTech (... - Outros',\n",
    "                  'Banco de Talentos - Eng de Dados - Júnior/Plen... - Outros Dados', 'Pessoa Engenheira de Dados Sênior - Outros Dados',\n",
    "                  'Data Insights Analyst - Outros Dados']\n",
    "\n",
    "for position in list_positions:\n",
    "    print(f'{position}: {title_classifier(position)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e99dfcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 19:43:45,354 - src.analysis.analysis_utils - INFO - Starting classifier test...\n",
      "2025-06-17 19:43:45,354 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Data & AI Analyst' | Expected: 'Outros Dados', Got: 'Analista de Dados'\n",
      "2025-06-17 19:43:45,368 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Especialista de operação de Dados - Vaga Afirmativa Feminino | Jurubatuba SP' | Expected: 'Outros Dados', Got: 'Analista de Dados'\n",
      "2025-06-17 19:43:45,399 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados (Sr/Especialista)' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,400 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados\n",
      "Trabalho Remoto\n",
      "Efetivo' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,402 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados Sr\n",
      "Trabalho Remoto\n",
      "Efetivo' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,403 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,405 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados Sr' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,405 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados Sênior' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,406 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados AWS' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,406 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa engenheira de dados senior' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,406 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa engenheira de dados senior' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,423 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Data Insights Analyst' | Expected: 'Outros Dados', Got: 'Analista de Dados'\n",
      "2025-06-17 19:43:45,424 - src.analysis.analysis_utils - WARNING - Test FAIL: 'DATA BUSINESS ANALYST' | Expected: 'Outros Dados', Got: 'Analista de Dados'\n",
      "2025-06-17 19:43:45,424 - src.analysis.analysis_utils - WARNING - Test FAIL: '* Especialista em Dados, Informações e Desenvolvimento de Painéis de Informação' | Expected: 'Outros Dados', Got: 'Analista de Dados'\n",
      "2025-06-17 19:43:45,424 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Especialista de Dados' | Expected: 'Outros Dados', Got: 'Analista de Dados'\n",
      "2025-06-17 19:43:45,432 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados Pleno' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,436 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Data Quality Analyst' | Expected: 'Outros Dados', Got: 'Analista de Dados'\n",
      "2025-06-17 19:43:45,442 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Artificial Intelligence Engineer' | Expected: 'Outros', Got: 'Engenheiro de IA'\n",
      "2025-06-17 19:43:45,442 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Artificial Intelligence Engineer, IgniteTech (Remote) - $100,000/year USD' | Expected: 'Outros', Got: 'Engenheiro de IA'\n",
      "2025-06-17 19:43:45,443 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Artificial Intelligence Engineer, IgniteTech (Remote) - $100,000/year USD' | Expected: 'Outros', Got: 'Engenheiro de IA'\n",
      "2025-06-17 19:43:45,454 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Artificial Intelligence Engineer' | Expected: 'Outros', Got: 'Engenheiro de IA'\n",
      "2025-06-17 19:43:45,461 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Especialista de Dados' | Expected: 'Outros Dados', Got: 'Analista de Dados'\n",
      "2025-06-17 19:43:45,463 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Artificial Intelligence Engineer, IgniteTech (Remote) - $100,000/year USD' | Expected: 'Outros', Got: 'Engenheiro de IA'\n",
      "2025-06-17 19:43:45,463 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Artificial Intelligence Engineer, IgniteTech (Remote) - $100,000/year USD' | Expected: 'Outros', Got: 'Engenheiro de IA'\n",
      "2025-06-17 19:43:45,475 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados Sênior (Vaga Afirmativa para Mulheres)' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,475 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados Pleno (Vaga afirmativa para profissionais com deficiência - PcD)' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,481 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados Sênior' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,486 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa engenheira de dados senior' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,492 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados Azure SR (Inglês avançado)' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,494 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Artificial Intelligence Engineer, IgniteTech (Remote) - $100,000/year USD' | Expected: 'Outros', Got: 'Engenheiro de IA'\n",
      "2025-06-17 19:43:45,496 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Artificial Intelligence Engineer, IgniteTech (Remote) - $100,000/year USD' | Expected: 'Outros', Got: 'Engenheiro de IA'\n",
      "2025-06-17 19:43:45,496 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Artificial Intelligence Engineer, IgniteTech (Remote) - $100,000/year USD' | Expected: 'Outros', Got: 'Engenheiro de IA'\n",
      "2025-06-17 19:43:45,504 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Especialista em Operação de Dados' | Expected: 'Outros Dados', Got: 'Analista de Dados'\n",
      "2025-06-17 19:43:45,509 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Data & Market Analyst JR/PL' | Expected: 'Outros Dados', Got: 'Analista de Dados'\n",
      "2025-06-17 19:43:45,510 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Especialista Dados I' | Expected: 'Outros Dados', Got: 'Analista de Dados'\n",
      "2025-06-17 19:43:45,511 - src.analysis.analysis_utils - WARNING - Test FAIL: '[Dados] Especialista em Análise de Dados' | Expected: 'Outros Dados', Got: 'Analista de Dados'\n",
      "2025-06-17 19:43:45,524 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados\n",
      "Trabalho Remoto\n",
      "Efetivo' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,535 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Especialista de Dados - São Paulo/SP' | Expected: 'Outros Dados', Got: 'Analista de Dados'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAIL Case 27: Input Title: 'Data & AI Analyst'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Analista de Dados'\n",
      "FAIL Case 371: Input Title: 'Especialista de operação de Dados - Vaga Afirmativa Feminino | Jurubatuba SP'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Analista de Dados'\n",
      "FAIL Case 1378: Input Title: 'Pessoa Engenheira de Dados (Sr/Especialista)'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 1386: Input Title: 'Pessoa Engenheira de Dados\n",
      "Trabalho Remoto\n",
      "Efetivo'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 1427: Input Title: 'Pessoa Engenheira de Dados Sr\n",
      "Trabalho Remoto\n",
      "Efetivo'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 1470: Input Title: 'Pessoa Engenheira de Dados'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 1473: Input Title: 'Pessoa Engenheira de Dados Sr'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 1475: Input Title: 'Pessoa Engenheira de Dados Sênior'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 1485: Input Title: 'Pessoa Engenheira de Dados AWS'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 1548: Input Title: 'Pessoa engenheira de dados senior'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 1559: Input Title: 'Pessoa engenheira de dados senior'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 2013: Input Title: 'Data Insights Analyst'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Analista de Dados'\n",
      "FAIL Case 2038: Input Title: 'DATA BUSINESS ANALYST'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Analista de Dados'\n",
      "FAIL Case 2194: Input Title: '* Especialista em Dados, Informações e Desenvolvimento de Painéis de Informação'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Analista de Dados'\n",
      "FAIL Case 2244: Input Title: 'Especialista de Dados'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Analista de Dados'\n",
      "FAIL Case 2343: Input Title: 'Pessoa Engenheira de Dados Pleno'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 2447: Input Title: 'Data Quality Analyst'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Analista de Dados'\n",
      "FAIL Case 2695: Input Title: 'Artificial Intelligence Engineer'\n",
      "  Expected: 'Outros'\n",
      "  Got:      'Engenheiro de IA'\n",
      "FAIL Case 2701: Input Title: 'Artificial Intelligence Engineer, IgniteTech (Remote) - $100,000/year USD'\n",
      "  Expected: 'Outros'\n",
      "  Got:      'Engenheiro de IA'\n",
      "FAIL Case 2706: Input Title: 'Artificial Intelligence Engineer, IgniteTech (Remote) - $100,000/year USD'\n",
      "  Expected: 'Outros'\n",
      "  Got:      'Engenheiro de IA'\n",
      "FAIL Case 3013: Input Title: 'Artificial Intelligence Engineer'\n",
      "  Expected: 'Outros'\n",
      "  Got:      'Engenheiro de IA'\n",
      "FAIL Case 3172: Input Title: 'Especialista de Dados'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Analista de Dados'\n",
      "FAIL Case 3221: Input Title: 'Artificial Intelligence Engineer, IgniteTech (Remote) - $100,000/year USD'\n",
      "  Expected: 'Outros'\n",
      "  Got:      'Engenheiro de IA'\n",
      "FAIL Case 3222: Input Title: 'Artificial Intelligence Engineer, IgniteTech (Remote) - $100,000/year USD'\n",
      "  Expected: 'Outros'\n",
      "  Got:      'Engenheiro de IA'\n",
      "FAIL Case 3462: Input Title: 'Pessoa Engenheira de Dados Sênior (Vaga Afirmativa para Mulheres)'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 3466: Input Title: 'Pessoa Engenheira de Dados Pleno (Vaga afirmativa para profissionais com deficiência - PcD)'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 3610: Input Title: 'Pessoa Engenheira de Dados Sênior'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 3800: Input Title: 'Pessoa engenheira de dados senior'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 3952: Input Title: 'Pessoa Engenheira de Dados Azure SR (Inglês avançado)'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 4013: Input Title: 'Artificial Intelligence Engineer, IgniteTech (Remote) - $100,000/year USD'\n",
      "  Expected: 'Outros'\n",
      "  Got:      'Engenheiro de IA'\n",
      "FAIL Case 4014: Input Title: 'Artificial Intelligence Engineer, IgniteTech (Remote) - $100,000/year USD'\n",
      "  Expected: 'Outros'\n",
      "  Got:      'Engenheiro de IA'\n",
      "FAIL Case 4015: Input Title: 'Artificial Intelligence Engineer, IgniteTech (Remote) - $100,000/year USD'\n",
      "  Expected: 'Outros'\n",
      "  Got:      'Engenheiro de IA'\n",
      "FAIL Case 4272: Input Title: 'Especialista em Operação de Dados'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Analista de Dados'\n",
      "FAIL Case 4377: Input Title: 'Data & Market Analyst JR/PL'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Analista de Dados'\n",
      "FAIL Case 4411: Input Title: 'Especialista Dados I'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Analista de Dados'\n",
      "FAIL Case 4426: Input Title: '[Dados] Especialista em Análise de Dados'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Analista de Dados'\n",
      "FAIL Case 4826: Input Title: 'Pessoa Engenheira de Dados\n",
      "Trabalho Remoto\n",
      "Efetivo'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 5114: Input Title: 'Especialista de Dados - São Paulo/SP'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Analista de Dados'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 19:43:45,535 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Especialista de Dados' | Expected: 'Outros Dados', Got: 'Analista de Dados'\n",
      "2025-06-17 19:43:45,535 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Especialista em Dados - Python' | Expected: 'Outros Dados', Got: 'Analista de Dados'\n",
      "2025-06-17 19:43:45,535 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados Pleno [AWS]' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,535 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados Pleno' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,543 - src.analysis.analysis_utils - WARNING - Test FAIL: 'AI Software Engineer (Remote)' | Expected: 'Outros', Got: 'Engenheiro de IA'\n",
      "2025-06-17 19:43:45,548 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados Sênior' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,549 - src.analysis.analysis_utils - WARNING - Test FAIL: 'IA Engineer Mid-Level' | Expected: 'Outros', Got: 'Engenheiro de IA'\n",
      "2025-06-17 19:43:45,557 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Especialista em Operação de Dados' | Expected: 'Outros Dados', Got: 'Analista de Dados'\n",
      "2025-06-17 19:43:45,559 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Data Insights Analyst' | Expected: 'Outros Dados', Got: 'Analista de Dados'\n",
      "2025-06-17 19:43:45,560 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados Pleno - Data Business' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,566 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Artificial Intelligence Engineer, LearnWith.AI (Remote) - $100,000/year USD' | Expected: 'Outros', Got: 'Engenheiro de IA'\n",
      "2025-06-17 19:43:45,567 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Artificial Intelligence Engineer, LearnWith.AI (Remote) - $100,000/year USD' | Expected: 'Outros', Got: 'Engenheiro de IA'\n",
      "2025-06-17 19:43:45,569 - src.analysis.analysis_utils - WARNING - Test FAIL: '9285847 - PESSOA ENGENHEIRA DE DADOS SÊNIOR' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,570 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados Sr.' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,573 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Data Ingestion Analyst' | Expected: 'Outros Dados', Got: 'Analista de Dados'\n",
      "2025-06-17 19:43:45,575 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados Sênior' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,578 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Artificial Intelligence Engineer Mid Level' | Expected: 'Outros', Got: 'Engenheiro de IA'\n",
      "2025-06-17 19:43:45,581 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,592 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados Sr' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,595 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de dados Pleno – Produtos Digitais' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,598 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados Sr' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,600 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Banco de Talentos - Eng de Dados - Júnior/Pleno | Exclusivo para Pessoas Diversas.' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,602 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados Pleno' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,604 - src.analysis.analysis_utils - WARNING - Test FAIL: 'PESSOA ENGENHEIRA DE DADOS JR - REMOTO' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,609 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa engenheira de dados senior' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,610 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados (Cosmos, Spark, Databricks)\n",
      "São Paulo - SP e Híbrido\n",
      "Efetivo' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,611 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Pessoa Engenheira de Dados (Cosmos, Spark, Databricks)' | Expected: 'Outros Dados', Got: 'Engenheiro de Dados'\n",
      "2025-06-17 19:43:45,615 - src.analysis.analysis_utils - WARNING - Test FAIL: 'Artificial Intelligence Engineer' | Expected: 'Outros', Got: 'Engenheiro de IA'\n",
      "2025-06-17 19:43:45,618 - src.analysis.analysis_utils - ERROR - Test results: 7425 passed, 66 failed out of 7491 cases.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAIL Case 5115: Input Title: 'Especialista de Dados'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Analista de Dados'\n",
      "FAIL Case 5132: Input Title: 'Especialista em Dados - Python'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Analista de Dados'\n",
      "FAIL Case 5136: Input Title: 'Pessoa Engenheira de Dados Pleno [AWS]'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 5140: Input Title: 'Pessoa Engenheira de Dados Pleno'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 5341: Input Title: 'AI Software Engineer (Remote)'\n",
      "  Expected: 'Outros'\n",
      "  Got:      'Engenheiro de IA'\n",
      "FAIL Case 5461: Input Title: 'Pessoa Engenheira de Dados Sênior'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 5472: Input Title: 'IA Engineer Mid-Level'\n",
      "  Expected: 'Outros'\n",
      "  Got:      'Engenheiro de IA'\n",
      "FAIL Case 5717: Input Title: 'Especialista em Operação de Dados'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Analista de Dados'\n",
      "FAIL Case 5778: Input Title: 'Data Insights Analyst'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Analista de Dados'\n",
      "FAIL Case 5800: Input Title: 'Pessoa Engenheira de Dados Pleno - Data Business'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 6010: Input Title: 'Artificial Intelligence Engineer, LearnWith.AI (Remote) - $100,000/year USD'\n",
      "  Expected: 'Outros'\n",
      "  Got:      'Engenheiro de IA'\n",
      "FAIL Case 6011: Input Title: 'Artificial Intelligence Engineer, LearnWith.AI (Remote) - $100,000/year USD'\n",
      "  Expected: 'Outros'\n",
      "  Got:      'Engenheiro de IA'\n",
      "FAIL Case 6064: Input Title: '9285847 - PESSOA ENGENHEIRA DE DADOS SÊNIOR'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 6067: Input Title: 'Pessoa Engenheira de Dados Sr.'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 6144: Input Title: 'Data Ingestion Analyst'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Analista de Dados'\n",
      "FAIL Case 6218: Input Title: 'Pessoa Engenheira de Dados Sênior'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 6276: Input Title: 'Artificial Intelligence Engineer Mid Level'\n",
      "  Expected: 'Outros'\n",
      "  Got:      'Engenheiro de IA'\n",
      "FAIL Case 6392: Input Title: 'Pessoa Engenheira de Dados'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 6680: Input Title: 'Pessoa Engenheira de Dados Sr'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 6792: Input Title: 'Pessoa Engenheira de dados Pleno – Produtos Digitais'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 6845: Input Title: 'Pessoa Engenheira de Dados Sr'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 6894: Input Title: 'Banco de Talentos - Eng de Dados - Júnior/Pleno | Exclusivo para Pessoas Diversas.'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 6971: Input Title: 'Pessoa Engenheira de Dados Pleno'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 7094: Input Title: 'PESSOA ENGENHEIRA DE DADOS JR - REMOTO'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 7187: Input Title: 'Pessoa engenheira de dados senior'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 7228: Input Title: 'Pessoa Engenheira de Dados (Cosmos, Spark, Databricks)\n",
      "São Paulo - SP e Híbrido\n",
      "Efetivo'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 7229: Input Title: 'Pessoa Engenheira de Dados (Cosmos, Spark, Databricks)'\n",
      "  Expected: 'Outros Dados'\n",
      "  Got:      'Engenheiro de Dados'\n",
      "FAIL Case 7385: Input Title: 'Artificial Intelligence Engineer'\n",
      "  Expected: 'Outros'\n",
      "  Got:      'Engenheiro de IA'\n",
      "\n",
      "Test results: 7425 passed, 66 failed out of 7491 cases.\n"
     ]
    }
   ],
   "source": [
    "jobs_classified = pd.read_csv('../data/processed/df_jobs_classified.csv')\n",
    "jobs_classified_tuple = list(zip(jobs_classified['job_title'], jobs_classified['classified_job_title']))\n",
    "\n",
    "test_classifier(jobs_classified_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7807549a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>classified_job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>Data Engineer SR - Apache Flink</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7273</th>\n",
       "      <td>Engenheiro de Dados AWS Sênior</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>Staff Data Engineer - User Knowledge</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>ENGENHEIRO DE DADOS II</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7457</th>\n",
       "      <td>ANALISTA COMERCIAL SR (ENGENHEIRO DE DADOS)</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6699</th>\n",
       "      <td>Engenheiro de dados senior</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7225</th>\n",
       "      <td>Data Engineer Senior</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6125</th>\n",
       "      <td>Engenheiro de Dados Sr</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7281</th>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>Engenheiro de Dados Cloud SR (DBT | Databricks...</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>Engenheiro de dados</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6538</th>\n",
       "      <td>Engenheiro de Dados Sênior (Inglês Avançado)</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6837</th>\n",
       "      <td>Engenheiro de Dados JR</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6420</th>\n",
       "      <td>Engenheiro de Dados (Oracle EBS -  Necessário ...</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7133</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>Datasphere Data Engineer | Senior</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>ENGENHEIRO(A) DE DADOS</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>Engenheiro de Dados Sênior</td>\n",
       "      <td>Engenheiro de Dados</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              job_title classified_job_title\n",
       "2344                    Data Engineer SR - Apache Flink  Engenheiro de Dados\n",
       "7273                     Engenheiro de Dados AWS Sênior  Engenheiro de Dados\n",
       "2404               Staff Data Engineer - User Knowledge  Engenheiro de Dados\n",
       "3155                             ENGENHEIRO DE DADOS II  Engenheiro de Dados\n",
       "7457        ANALISTA COMERCIAL SR (ENGENHEIRO DE DADOS)  Engenheiro de Dados\n",
       "6699                         Engenheiro de dados senior  Engenheiro de Dados\n",
       "3127                                Engenheiro de Dados  Engenheiro de Dados\n",
       "7225                               Data Engineer Senior  Engenheiro de Dados\n",
       "2333                                      Data Engineer  Engenheiro de Dados\n",
       "6125                             Engenheiro de Dados Sr  Engenheiro de Dados\n",
       "7281                                Engenheiro de Dados  Engenheiro de Dados\n",
       "1461  Engenheiro de Dados Cloud SR (DBT | Databricks...  Engenheiro de Dados\n",
       "1475                                Engenheiro de dados  Engenheiro de Dados\n",
       "6538       Engenheiro de Dados Sênior (Inglês Avançado)  Engenheiro de Dados\n",
       "6837                             Engenheiro de Dados JR  Engenheiro de Dados\n",
       "6420  Engenheiro de Dados (Oracle EBS -  Necessário ...  Engenheiro de Dados\n",
       "7133                               Senior Data Engineer  Engenheiro de Dados\n",
       "2406                  Datasphere Data Engineer | Senior  Engenheiro de Dados\n",
       "1413                             ENGENHEIRO(A) DE DADOS  Engenheiro de Dados\n",
       "1820                         Engenheiro de Dados Sênior  Engenheiro de Dados"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_classified[jobs_classified['classified_job_title']=='Engenheiro de Dados'][['job_title', 'classified_job_title']].sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c478bc94",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e3e4d7",
   "metadata": {},
   "source": [
    "# Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97150183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1944d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_locations(df: pd.DataFrame, location_col: str = 'location') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardizes location data into separate city, state, and country columns.\n",
    "    Handles cases like \"São Paulo, Brasil\" and \"Distrito Federal, Brasil\" correctly.\n",
    "    Also handles \"e Região\" patterns for state capitals.\n",
    "    \"\"\"\n",
    "    \n",
    "    df['city'] = None\n",
    "    df['state'] = None\n",
    "    df['country'] = 'Brasil'\n",
    "    \n",
    "    brazilian_states = {\n",
    "        'AC': 'Acre', 'AL': 'Alagoas', 'AP': 'Amapá', 'AM': 'Amazonas',\n",
    "        'BA': 'Bahia', 'CE': 'Ceará', 'DF': 'Distrito Federal',\n",
    "        'ES': 'Espírito Santo', 'GO': 'Goiás', 'MA': 'Maranhão',\n",
    "        'MT': 'Mato Grosso', 'MS': 'Mato Grosso do Sul',\n",
    "        'MG': 'Minas Gerais', 'PA': 'Pará', 'PB': 'Paraíba',\n",
    "        'PR': 'Paraná', 'PE': 'Pernambuco', 'PI': 'Piauí',\n",
    "        'RJ': 'Rio de Janeiro', 'RN': 'Rio Grande do Norte',\n",
    "        'RS': 'Rio Grande do Sul', 'RO': 'Rondônia',\n",
    "        'RR': 'Roraima', 'SC': 'Santa Catarina',\n",
    "        'SP': 'São Paulo', 'SE': 'Sergipe', 'TO': 'Tocantins'\n",
    "    }\n",
    "    \n",
    "    state_capitals = {\n",
    "        'Rio Branco': 'AC', 'Maceió': 'AL', 'Macapá': 'AP', 'Manaus': 'AM',\n",
    "        'Salvador': 'BA', 'Fortaleza': 'CE', 'Brasília': 'DF', 'Vitória': 'ES',\n",
    "        'Goiânia': 'GO', 'São Luís': 'MA', 'Cuiabá': 'MT', 'Campo Grande': 'MS',\n",
    "        'Belo Horizonte': 'MG', 'Belém': 'PA', 'João Pessoa': 'PB', 'Curitiba': 'PR',\n",
    "        'Recife': 'PE', 'Teresina': 'PI', 'Rio De Janeiro': 'RJ', 'Natal': 'RN',\n",
    "        'Porto Alegre': 'RS', 'Porto Velho': 'RO', 'Boa Vista': 'RR', 'Florianópolis': 'SC',\n",
    "        'São Paulo': 'SP', 'Aracaju': 'SE', 'Palmas': 'TO'\n",
    "    }\n",
    "    \n",
    "    state_mapping = {**{v: k for k, v in brazilian_states.items()}, **brazilian_states}\n",
    "    \n",
    "    state_names = set(brazilian_states.values())\n",
    "    state_abbrevs = set(brazilian_states.keys())\n",
    "    \n",
    "    def extract_location(location):\n",
    "        if pd.isna(location):\n",
    "            return (None, None, None)\n",
    "            \n",
    "        location = str(location).strip()\n",
    "\n",
    "        if location.lower() in ['brasil']:\n",
    "            return (None, None, 'Brasil')\n",
    "        \n",
    "        if location in state_names or location in state_abbrevs:\n",
    "            state_code = location if location in state_abbrevs else state_mapping.get(location)\n",
    "            return (None, state_code, 'Brasil')\n",
    "            \n",
    "        match = re.match(r'^(?P<state>[^,]+),\\s*Brasil$', location, re.IGNORECASE)\n",
    "        if match and match.group('state') in state_names:\n",
    "            state_name = match.group('state')\n",
    "            return (None, state_mapping.get(state_name), 'Brasil')\n",
    "        \n",
    "        match = re.match(r'^(?P<city>.+)\\s+e\\s+Região$', location)\n",
    "        if match:\n",
    "            city = match.group('city').strip().title()\n",
    "            state = state_capitals.get(city)\n",
    "            return (city, state, 'Brasil')\n",
    "        \n",
    "        match = re.match(r'^(?P<city>[^,]+),\\s*(?P<state>[A-Z]{2})$', location)\n",
    "        if match:\n",
    "            return (match.group('city').title(), match.group('state').upper(), 'Brasil')\n",
    "        \n",
    "        match = re.match(r'^(?P<city>[^,]+),\\s*(?P<state>.+)$', location)\n",
    "        if match:\n",
    "            state = match.group('state').strip()\n",
    "            \n",
    "            if state.lower() in ['brasil', 'brazil']:\n",
    "                city_name = match.group('city').title()\n",
    "                return (city_name, state_capitals.get(city_name), 'Brasil')\n",
    "                \n",
    "            if state in state_names or state in state_abbrevs:\n",
    "                state_code = state if state in state_abbrevs else state_mapping.get(state)\n",
    "                return (match.group('city').title(), state_code, 'Brasil')\n",
    "            \n",
    "            return (match.group('city').title(), None, 'Brasil')\n",
    "        \n",
    "        city_name = location.title()\n",
    "        if city_name in state_capitals:\n",
    "            return (city_name, state_capitals.get(city_name), 'Brasil')\n",
    "        \n",
    "        return (city_name, None, 'Brasil')\n",
    "    \n",
    "    df[['city', 'state', 'country']] = df[location_col].apply(\n",
    "        lambda x: pd.Series(extract_location(x))\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fb4c64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "brazilian_states = {\n",
    "    'AC': 'Acre', 'AL': 'Alagoas', 'AP': 'Amapá', 'AM': 'Amazonas',\n",
    "    'BA': 'Bahia', 'CE': 'Ceará', 'DF': 'Distrito Federal',\n",
    "    'ES': 'Espírito Santo', 'GO': 'Goiás', 'MA': 'Maranhão',\n",
    "    'MT': 'Mato Grosso', 'MS': 'Mato Grosso Do Sul',\n",
    "    'MG': 'Minas Gerais', 'PA': 'Pará', 'PB': 'Paraíba',\n",
    "    'PR': 'Paraná', 'PE': 'Pernambuco', 'PI': 'Piauí',\n",
    "    'RJ': 'RioDe Janeiro', 'RN': 'Rio Grande Do Norte',\n",
    "    'RS': 'Rio Grande Do Sul', 'RO': 'Rondônia',\n",
    "    'RR': 'Roraima', 'SC': 'Santa Catarina',\n",
    "    'SP': 'São Paulo', 'SE': 'Sergipe', 'TO': 'Tocantins'\n",
    "}\n",
    "\n",
    "# Brazilian state capitals mapping (capital city: state abbreviation)\n",
    "state_capitals = {\n",
    "    'Rio Branco': 'AC', 'Maceió': 'AL', 'Macapá': 'AP', 'Manaus': 'AM',\n",
    "    'Salvador': 'BA', 'Fortaleza': 'CE', 'Brasília': 'DF', 'Vitória': 'ES',\n",
    "    'Goiânia': 'GO', 'São Luís': 'MA', 'Cuiabá': 'MT', 'Campo Grande': 'MS',\n",
    "    'Belo Horizonte': 'MG', 'Belém': 'PA', 'João Pessoa': 'PB', 'Curitiba': 'PR',\n",
    "    'Recife': 'PE', 'Teresina': 'PI', 'Rio De Janeiro': 'RJ', 'Natal': 'RN',\n",
    "    'Porto Alegre': 'RS', 'Porto Velho': 'RO', 'Boa Vista': 'RR', 'Florianópolis': 'SC',\n",
    "    'São Paulo': 'SP', 'Aracaju': 'SE', 'Palmas': 'TO'\n",
    "}\n",
    "\n",
    "# Create bidirectional mapping for state names and abbreviations\n",
    "state_mapping = {**{v: k for k, v in brazilian_states.items()}, **brazilian_states}\n",
    "\n",
    "    # Set of state names (to check if a location is a state)\n",
    "state_names = set(brazilian_states.values())\n",
    "state_abbrevs = set(brazilian_states.keys())\n",
    "\n",
    "def extract_location(location):\n",
    "    if pd.isna(location):\n",
    "        return (None, None, None)\n",
    "        \n",
    "    location = str(location).strip()\n",
    "    \n",
    "    # Handle country-level or remote cases\n",
    "    if location.lower() in ['brasil', 'brazil', 'remote', 'remoto']:\n",
    "        return (None, None, 'Brasil')\n",
    "    \n",
    "    # Handle special case of \"Distrito Federal, Brasil\" and other direct state references\n",
    "    if location in state_names or location in state_abbrevs:\n",
    "        state_code = location if location in state_abbrevs else state_mapping.get(location)\n",
    "        return (None, state_code, 'Brasil')\n",
    "        \n",
    "    # Check for state directly followed by country (\"Distrito Federal, Brasil\")\n",
    "    match = re.match(r'^(?P<state>[^,]+),\\s*Brasil$', location, re.IGNORECASE)\n",
    "    if match and match.group('state') in state_names:\n",
    "        state_name = match.group('state')\n",
    "        return (None, state_mapping.get(state_name), 'Brasil')\n",
    "    \n",
    "    # Pattern for \"City e Região\" (e.g., \"São Paulo e Região\")\n",
    "    # Important: What comes with \"e Região\" is ALWAYS the city\n",
    "    match = re.match(r'^(?P<city>.+)\\s+e\\s+Região$', location)\n",
    "    if match:\n",
    "        city = match.group('city').strip().title()\n",
    "        # Get state from the capital mapping\n",
    "        state = state_capitals.get(city)\n",
    "        return (city, state, 'Brasil')\n",
    "    \n",
    "    # Pattern for \"City, ST\" (e.g., \"São Paulo, SP\")\n",
    "    match = re.match(r'^(?P<city>[^,]+),\\s*(?P<state>[A-Z]{2})$', location)\n",
    "    if match:\n",
    "        return (match.group('city').title(), match.group('state').upper(), 'Brasil')\n",
    "    \n",
    "    # Pattern for \"City, State\" (e.g., \"São Paulo, São Paulo\")\n",
    "    match = re.match(r'^(?P<city>[^,]+),\\s*(?P<state>.+)$', location)\n",
    "    if match:\n",
    "        state = match.group('state').strip()\n",
    "        \n",
    "        # Check if state is actually a country reference\n",
    "        if state.lower() in ['brasil', 'brazil']:\n",
    "            city_name = match.group('city').title()\n",
    "            # Check if city is a state capital\n",
    "            return (city_name, state_capitals.get(city_name), 'Brasil')\n",
    "            \n",
    "        # Check if the supposed state is actually a state\n",
    "        if state in state_names or state in state_abbrevs:\n",
    "            state_code = state if state in state_abbrevs else state_mapping.get(state)\n",
    "            return (match.group('city').title(), state_code, 'Brasil')\n",
    "        \n",
    "        # Otherwise assume first part is city, second part unknown\n",
    "        return (match.group('city').title(), None, 'Brasil')\n",
    "    \n",
    "    city_name = location.title()\n",
    "    # Check if the city is a state capital\n",
    "    if city_name in state_capitals:\n",
    "        return (city_name, state_capitals.get(city_name), 'Brasil')\n",
    "    \n",
    "    return (city_name, None, 'Brasil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1707c048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rio Verde, Goiás, Brasil</td>\n",
       "      <td>Rio Verde</td>\n",
       "      <td>None</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   location       city state country\n",
       "0  Rio Verde, Goiás, Brasil  Rio Verde  None  Brasil"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_test = {'location': ['Rio Verde, Goiás, Brasil']}\n",
    "df = pd.DataFrame(dict_test)\n",
    "standardize_locations(df, 'location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb5d3029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, 'Brasil')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_location('Brasil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9184ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_location(test_cases):\n",
    "    \"\"\"Test function to verify classifier behavior\"\"\"\n",
    "\n",
    "    failed = 0\n",
    "    for location, expected in test_cases:\n",
    "        result = extract_location(location)\n",
    "        if result != expected:\n",
    "            print(f\"FAIL: '{location}'\")\n",
    "            print(f\"  Expected: {expected}\")\n",
    "            print(f\"  Got:      {result}\")\n",
    "            failed += 1\n",
    "\n",
    "    print(f\"\\nTest results: {len(test_cases)-failed} passed, {failed} failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "870cdc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    ('São Paulo, SP', ('São Paulo', 'SP', 'Brasil')),\n",
    "    ('Brasil', (None, None, 'Brasil')),\n",
    "    ('São Paulo e Região', ('São Paulo', 'SP', 'Brasil')),\n",
    "    ('Rio de Janeiro e Região', ('Rio De Janeiro', 'RJ', 'Brasil')),\n",
    "    ('Distrito Federal, Brasil', (None, 'DF', 'Brasil')),\n",
    "    ('Naviraí, MS', ('Naviraí', 'MS', 'Brasil'))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80406d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test results: 6 passed, 0 failed\n"
     ]
    }
   ],
   "source": [
    "test_location(test_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d254287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.read_csv('../data/raw/jobs_data.csv')\n",
    "job_copy = jobs.copy()\n",
    "df = standardize_locations(jobs, location_col='location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6dd00691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>work_model</th>\n",
       "      <th>keyword</th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>time_posted</th>\n",
       "      <th>num_applicants</th>\n",
       "      <th>xp_level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_sectors</th>\n",
       "      <th>job_description</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [job_id, work_model, keyword, scrape_date, job_title, company_name, location, time_posted, num_applicants, xp_level, job_type, job_sectors, job_description, city, state, country]\n",
       "Index: []"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['location'].str.contains('remoto')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e3078ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Barueri', 'São Paulo', 'Curitiba', 'Maracanaú', 'Brasília',\n",
       "       'Guará', 'Campinas', 'Fortaleza', 'Blumenau', 'Indaial',\n",
       "       'Rio De Janeiro', 'Porto Alegre', 'Campo Grande', 'Contagem',\n",
       "       'Mogi Das Cruzes', 'Uberlândia', 'Caxias Do Sul', 'Cravinhos',\n",
       "       'Pereiro', 'Macaé', 'Itajaí', 'Osasco', 'Betim', 'Palotina', None,\n",
       "       'Goiânia', 'Serra', 'Novo Hamburgo', 'Tijucas', 'Maringá',\n",
       "       'Cachoeirinha', 'Joinville', 'Vitória', 'Sorocaba',\n",
       "       'Ribeirão Preto', 'Mossoró', 'Marília', 'Jaraguá Do Sul', 'Arcos',\n",
       "       'Dois Irmãos', 'São Bernardo Do Campo', 'Várzea Grande',\n",
       "       'Belo Horizonte', 'Aracaju', 'Pato Branco', 'Franca', 'Rio Do Sul',\n",
       "       'Ibirama', 'Manaus', 'Recife', 'Embu Das Artes', 'Eldorado Do Sul',\n",
       "       'Viçosa', 'Leopoldina', 'Monte Belo', 'Vila Velha', 'Londrina',\n",
       "       'Salvador', 'Naviraí', 'Morrinhos', 'Cuiabá', 'Florianópolis',\n",
       "       'Jundiaí', 'Belém', 'Teresina', 'São José Do Rio Preto',\n",
       "       'Santo André', 'Santa Rosa', 'Matão', 'Sumaré',\n",
       "       'Lucas Do Rio Verde', 'Paulínia', 'Ponta Grossa', 'Paragominas',\n",
       "       'Carlos Barbosa', 'Tailândia', 'Ampére', 'Taguatinga', 'Guarulhos',\n",
       "       'Toledo', 'Igrejinha', 'Pouso Alegre', 'Santa Cruz Do Sul',\n",
       "       'Garibaldi', 'Rio Grande', 'Nova Lima', 'Nova Santa Rita',\n",
       "       'Piracicaba', 'Santos', 'Vespasiano', 'Arujá', 'Cascavel',\n",
       "       'Lorena', 'Indaiatuba', 'São João Del-Rei', 'Ribeirão Grande',\n",
       "       'Dourados', 'Valinhos', 'Cabo De Santo Agostinho', 'Agudos',\n",
       "       'Alto Horizonte', 'São José Dos Pinhais', 'Pinhais', 'Canoas',\n",
       "       'Guarapuava', 'Barretos', 'Bebedouro', 'Hortolândia', 'Palhoça',\n",
       "       'Limeira', 'Nova Iguaçu', 'Jaboatão Dos Guararapes', 'Natal',\n",
       "       'Ribeirão', 'São Luis', 'São José Dos Campos', 'Jandira',\n",
       "       'Parauapebas', 'Eusébio', 'Itapevi', 'Ji-Paraná',\n",
       "       'Poços De Caldas', 'Cambé', 'Belem', 'Serra Do Salitre', 'Chapecó',\n",
       "       'Barão De Cocais', 'Santa Maria Do Pará', 'São Bento Do Sul',\n",
       "       'Cajamar', 'Manacapuru', 'Barbacena', 'Gavião Peixoto', 'Colina',\n",
       "       'Jaguariúna', 'Rio Brilhante', 'Mato Dentro', 'Lagoa Da Prata',\n",
       "       'Sertãozinho', 'Itabira', 'Ouroeste', 'Ibaté', 'Olímpia',\n",
       "       'Franco Da Rocha', 'Canaã Dos Carajás', 'Mariana',\n",
       "       'Angra Dos Reis', 'Itaberaí', 'Guaratinguetá', 'Cataguases',\n",
       "       'Ouro Branco', 'São Caetano Do Sul', 'Corumbá',\n",
       "       'São João Da Barra', 'Camaçari', 'Cachoeiro De Itapemirim',\n",
       "       'Aparecida De Goiânia', 'Cabreúva', 'Cocalinho', 'Candeias',\n",
       "       'Guadalupe', 'Cruz Alta', 'Barcarena', 'São Francisco Do Conde',\n",
       "       'Navegantes', 'Ipojuca', 'Içara', 'Balneário Camboriú',\n",
       "       'Várzea Da Palma', 'Concórdia', 'Americana', 'Varginha',\n",
       "       'Boa Vista', 'Niterói', \"Sant'Ana Do Livramento\", 'Itajubá',\n",
       "       'Montes Claros', 'Bagé', 'Luís Eduardo Magalhães',\n",
       "       'Campina Grande', 'Sorriso', 'São Carlos', 'Videira', 'Uruguaiana',\n",
       "       'Tapejara', 'Taubaté', 'Curvelo', 'São José', 'São Luís',\n",
       "       'Juiz De Fora', 'Uberaba', 'Guaíba', 'Pedreira', 'Vinhedo',\n",
       "       'Engenheiro Beltrão', 'Porto Feliz', 'Suzano', 'Diadema',\n",
       "       'Montenegro', 'Cariacica', \"Santa Bárbara D'Oeste\", 'Cotia',\n",
       "       'Linhares', 'Caruaru', 'Olinda', 'Campo Largo', 'Parnamirim',\n",
       "       'Campos Dos Goytacazes', 'Duque De Caxias', 'Resende', 'Guarapari',\n",
       "       'Porto Velho', 'Gaspar', 'Marabá', 'Castanhal', 'Santarém',\n",
       "       'Anápolis', 'Rio Verde', 'Brusque', 'Guaramirim', 'Criciúma',\n",
       "       'Timbó', 'Lages', 'Biguaçu', 'Tubarão', 'Porto Belo', 'Itapema',\n",
       "       'Paranaguá', 'Campina Grande Do Sul', 'Colombo',\n",
       "       'Francisco Beltrão', 'Fazenda Rio Grande', 'Arapongas',\n",
       "       'Foz Do Iguaçu', 'Cabedelo', 'Caratinga', 'João Pessoa',\n",
       "       'Arapiraca', 'Maceió', 'Viana', 'Rio Branco', 'Petrolina',\n",
       "       'Caucaia', 'Quatro Barras', 'Araquari', 'Feira De Santana',\n",
       "       'Vitória Da Conquista', 'Três Lagoas', 'Araucária',\n",
       "       'Patos De Minas', 'Lavras', 'Divinópolis', 'Ribeirão Das Neves',\n",
       "       'Extrema', 'Governador Valadares', 'Sete Lagoas', 'Ipatinga',\n",
       "       'Juazeiro Do Norte', 'Imperatriz', 'Itatiba', 'Primavera Do Leste',\n",
       "       'Sinop', 'Passo Fundo', 'Taboão Da Serra', 'Bragança Paulista',\n",
       "       'Guarujá', 'Araras', 'Rio Claro', 'Presidente Prudente',\n",
       "       'Praia Grande', 'Louveira', 'Mogi Guaçu', 'Nova Odessa',\n",
       "       'Pindamonhangaba', 'Atibaia', 'Araraquara', 'Itu', 'Caraguatatuba',\n",
       "       'Ribeirão Pires', 'Araçatuba', 'Caieiras', 'Itapecerica Da Serra',\n",
       "       'Mauá', 'Jacareí', 'Votorantim', 'Santana De Parnaíba', 'Bauru',\n",
       "       'Cabo Frio', 'Petrópolis', 'São Gonçalo', 'Rio Das Ostras',\n",
       "       'Volta Redonda', 'Campo Bom', 'São Leopoldo', 'Ijuí', 'Gramado',\n",
       "       'Capão Da Canoa', 'Alvorada', 'Esteio', 'Pelotas',\n",
       "       'Bento Gonçalves', 'Flores Da Cunha', 'Santa Maria',\n",
       "       'Estância Velha', 'Sapucaia Do Sul', 'Itabirito', 'Farroupilha',\n",
       "       'Conselheiro Lafaiete', 'Lagoa Santa', 'Viamão', 'Álvares Machado',\n",
       "       'Rondonópolis', 'Macapá', 'Ituiutaba', 'Camboriú', 'Ananindeua',\n",
       "       'Sarzedo', 'São José Do Inhacorá', 'Cunha Porã', 'Fundão',\n",
       "       'Gravataí', 'Palmas', 'Itupeva', 'Mucuri', 'Santa Luzia',\n",
       "       'Itapeva', 'Consolação', 'Piracaia', 'Jaú', 'Itaperuçu', 'Cubatão',\n",
       "       'Conceição Do Mato Dentro', 'Leme', 'Barro Alto', 'Valparaíso',\n",
       "       'Ouro Preto', 'Itajai', 'Cachoeira Do Sul', 'São Bento Do Una',\n",
       "       'Montanha', 'Alegria', 'Eunápolis', 'Lajeado', 'Caarapó', 'Uruaçu',\n",
       "       'Congonhas', 'Santo Augusto', 'Timóteo', 'Descalvado',\n",
       "       'São Miguel Do Oeste', 'Registro', 'Itaboraí',\n",
       "       'Vargem Grande Paulista', 'Santa Bárbara', 'Guanambi', 'Samambaia',\n",
       "       'São Sebastião', 'Caçador', 'Amparo', 'Lauro De Freitas',\n",
       "       'Monções', 'São Joaquim Da Barra', 'Simões Filho', 'Ilhéus',\n",
       "       'Barreiras', 'Avaré', 'Nossa Senhora Do Socorro',\n",
       "       'Cornélio Procópio', 'Barra Do Turvo', 'Itapetininga',\n",
       "       'Agrovila 29', 'Lins', 'Pontes E Lacerda', 'Maricá',\n",
       "       'São Pedro Da Aldeia', 'Cacoal', 'Planta', 'Rio Bananal',\n",
       "       'Salto De Pirapora', 'Cajazeiras', 'Itirapina', 'Brotas',\n",
       "       'Salgueiro', 'Aripuanã', 'Barra Funda', 'Itatiaia',\n",
       "       'Santa Rita De Ibitipoca', 'Barra Mansa', 'Mata De São João',\n",
       "       'Valença', 'Ibiúna', 'Abreu E Lima', 'Cunhataí', 'Rio Quente',\n",
       "       'Mangaratiba', 'São Lourenço Do Oeste', 'São João De Meriti',\n",
       "       'Mirassol', 'Bady Bassitt', 'Porto Seguro', 'Correntina',\n",
       "       'Parnaíba', 'Araguaína', 'Goiás', 'Santo Anastácio',\n",
       "       'Bom Princípio', 'Cristalina', 'Várzea Paulista', 'Colômbia',\n",
       "       'Tatuí', 'Crixás', 'Riacho Dos Machados', 'Paracatu', 'Jeceaba',\n",
       "       'Quirinópolis', 'Três De Maio', 'Paraíso Do Tocantins', 'Cruz',\n",
       "       'Lauro Müller', 'Pedro Afonso', 'Benevides', 'Paranavaí',\n",
       "       'Santo Antônio Do Monte', 'Mogi Mirim', 'Craíbas', 'Europa',\n",
       "       'Horizontina', 'São Gonçalo Do Amarante', 'Tucumã', 'Morada Nova',\n",
       "       'Juruti'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['city'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1faea274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = (job_copy[['city', 'state', 'country']] != df[['city', 'state', 'country']])\n",
    "# # Show both DataFrames side by side where they differ\n",
    "# differences = pd.concat([job_copy[mask.any(axis=1)], df[mask.any(axis=1)]], axis=1, keys=['job_copy', 'df'])\n",
    "# differences[[('job_copy', 'city'), ('job_copy', 'state'), ('job_copy', 'country'), ('df', 'city'), ('df', 'state'), ('df', 'country')]].sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
